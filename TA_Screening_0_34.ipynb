{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from yahoo_fin import stock_info as si\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import talib\n",
    "from talib import *\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from LSSVMRegression import LSSVMRegression\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators():\n",
    "        \n",
    "    R_S_I = RSI(df['Adj Close'], timeperiod=slow)\n",
    "    E_M_A = EMA(df['Adj Close'], timeperiod=fast)\n",
    "    macd, macdsig, macdhist = MACD(df['Adj Close'], fastperiod=fast, slowperiod=slow, signalperiod=really_fast)\n",
    "    mfi = MFI(df['High'], df['Low'], df['Adj Close'],df['Volume'],timeperiod=fast)\n",
    "    slowk, slowd = STOCH(df['High'], df['Low'], df['Adj Close'], fastk_period=fast, \n",
    "                         slowk_period=slow, slowk_matype=0, slowd_period=slow, slowd_matype=0)\n",
    "    \n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    df['ema'] = E_M_A\n",
    "    df['rsi'] = R_S_I\n",
    "    df['macd'] = macd\n",
    "    df['macdsig'] = macdsig\n",
    "    df['macdhist'] = macdhist\n",
    "    df['mfi'] = mfi\n",
    "    df['slowK'] = slowk\n",
    "    df['slowD'] = slowd\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####\n",
    "    \n",
    "    \n",
    "\n",
    "    #76 vars\n",
    "\n",
    "    #are_all_zero = (test_TA == 0).all()\n",
    "    #true if all values are 0\n",
    "    #false if contain a non 0'''\n",
    "\n",
    "    df.drop(['Close'], axis =1, inplace = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag(num_lag_cols, this_df):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    '''df['ema'] = E_M_A\n",
    "    df['rsi'] = R_S_I\n",
    "    df['macd'] = macd\n",
    "    df['macdsig'] = macdsig\n",
    "    df['macdhist'] = macdhist\n",
    "    df['mfi'] = mfi\n",
    "    df['slowK'] = slowk\n",
    "    df['slowD'] = slowd'''\n",
    "    \n",
    "    lag_cols = ['open',\n",
    "                 'high',\n",
    "                 'low',\n",
    "                 'adj_close',\n",
    "                 'volume',\n",
    "                 'ema',\n",
    "                 'rsi',\n",
    "                 'macd',\n",
    "                 'macdsig',\n",
    "                 'macdhist',\n",
    "                 'mfi',\n",
    "                 'slowk',\n",
    "                 'slowd']\n",
    "\n",
    "    shift_range = [x+1 for x in range(num_lag_cols)]\n",
    "\n",
    "    for shift in shift_range:\n",
    "        train_shift = this_df[merging_keys + lag_cols].copy()\n",
    "\n",
    "        # E.g. order_day of 0 becomes 1, for shift = 1.\n",
    "        # So when this is merged with order_day of 1 in df, this will represent lag of 1.\n",
    "        train_shift['order_day'] = train_shift['order_day'] + shift\n",
    "\n",
    "        foo = lambda x: '{}_lag_{}'.format(x, shift) if x in lag_cols else x\n",
    "        train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "        this_df = pd.merge(this_df, train_shift, on=merging_keys, how='left') #.fillna(0)\n",
    "\n",
    "    del train_shift\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "\n",
    "    print(f\"completed lagging in {tic_toc:0.4f} min\")\n",
    "    \n",
    "\n",
    "    return this_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scale(num_interval_lag):\n",
    "\n",
    "    cols_to_scale = ['open',#\n",
    "                     'high',#\n",
    "                     'low',#\n",
    "                     'adj_close',#\n",
    "                     'volume',#\n",
    "                     'ema',#\n",
    "                     'rsi',#\n",
    "                     'macd',#\n",
    "                     'macdsig',#\n",
    "                     'macdhist',#\n",
    "                     'mfi',#\n",
    "                     'slowk',#\n",
    "                     'slowd']#\n",
    "                    \n",
    "\n",
    "    for i in range(1,num_interval_lag+1):\n",
    "        cols_to_scale.append(\"ema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsi_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"volume_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"adj_close_lag_\"+str(i))\n",
    "        \n",
    "        cols_to_scale.append(\"open_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"high_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"low_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"macd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdhist_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"mfi_lag_\"+str(i))\n",
    "      \n",
    "    return cols_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'MSFT'\n",
    "\n",
    "start_date = datetime.datetime.now() - datetime.timedelta(days=59)\n",
    "\n",
    "end_date = datetime.datetime.now()\n",
    "\n",
    "df = pdr.get_data_yahoo(stock, start=start_date, end=end_date, interval = \"2m\", prepost = True)\n",
    "\n",
    "#df = pdr.get_data_yahoo(stock, period = \"max\", interval = \"1d\", prepost = True)\n",
    "\n",
    "#df.index = df.index.tz_localize(None)\n",
    "\n",
    "'''#2 min ticker\n",
    "# 30 intervals = 1 hour << OLD\n",
    "# 195 intervals = trading day'''\n",
    "                                            # there are more intervals that we can use / change\n",
    "really_fast = 30\n",
    "fast = 60\n",
    "slow = 90\n",
    "\n",
    "add_indicators()\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "# Change all column headings to be lower case, and remove spacing\n",
    "df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n",
    "\n",
    "df['order_day'] = [x for x in list(range(len(df)))]\n",
    "# merging_keys\n",
    "\n",
    "\n",
    "# Get difference between high and low of each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-sheet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_keys = ['order_day']\n",
    "\n",
    "num_interval_lag = 30\n",
    "\n",
    "df = add_lag(num_interval_lag, df)\n",
    "\n",
    "#df['adj_close'] = df['adj_close'].shift(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "\n",
    "df['adj_close'] = df['adj_close'].shift(-window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rem = ['open',\n",
    "                 'high',\n",
    "                 'low',\n",
    "                 'volume',\n",
    "                 'ema',\n",
    "                 'rsi',\n",
    "                 'macd',\n",
    "                 'macdsig',\n",
    "                 'macdhist',\n",
    "                 'mfi',\n",
    "                 'slowk',\n",
    "                 'slowd',\n",
    "                 'order_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_vals_list = df['adj_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols_to_rem, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#close_vals_list = df['adj_close']\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#df.fillna(0, inplace=True)\n",
    "\n",
    "#BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "num_test = int(.10*len(df))\n",
    "num_train = len(df) - num_test\n",
    "\n",
    "# Split into train, cv, and test\n",
    "train = df[:num_train]\n",
    "test = df[num_train:]\n",
    "\n",
    "#print(test['datetime'].iloc[[-1]])\n",
    "#print(test['test_labels'].iloc[[-1]])\n",
    "\n",
    "train_close_vals = close_vals_list[:num_train]\n",
    "test_close_vals = close_vals_list[num_train:]\n",
    "\n",
    "#test_dates_list = test['date']\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates_list = test['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates_list = train['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = add_scale(num_interval_lag)\n",
    "#cols_to_scale.remove(cols_to_rem)\n",
    "\n",
    "# Do scaling for train set\n",
    "# Here we only scale the train dataset, and not the entire dataset to prevent information leak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in cols_to_rem:\n",
    "\n",
    "    if element in cols_to_scale:\n",
    "\n",
    "        cols_to_scale.remove(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-grounds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "scaler = QuantileTransformer()\n",
    "\n",
    "scaler.fit(train[cols_to_scale])\n",
    "train_scaled = scaler.transform(train[cols_to_scale])\n",
    "\n",
    "# Convert the numpy array back into pandas dataframe\n",
    "\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=cols_to_scale)\n",
    "\n",
    "train_scaled = train_scaled[slow:]\n",
    "train = train[slow:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling test dataset\n",
    "\n",
    "\n",
    "#test = np.array(test, dtype=np.longdouble)\n",
    "scaler.fit(test[cols_to_scale])\n",
    "test_scaled = scaler.transform(test[cols_to_scale])\n",
    "\n",
    "# Convert the numpy array back into pandas dataframe\n",
    "\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=cols_to_scale)\n",
    "\n",
    "features = cols_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_y_test = test_scaled['adj_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-small",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('adj_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('adj_close' in features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('adj_close' in train_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features.remove(target)\n",
    "\n",
    "# Split into X and y\n",
    "'''X_train_scaled = train_scaled[features]\n",
    "y_train_scaled = train['labels']\n",
    "\n",
    "X_test_scaled = test_scaled[features]\n",
    "y_test_scaled = test['labels']'''\n",
    "\n",
    "X_train = train_scaled[features]\n",
    "y_train = train_scaled['adj_close']\n",
    "\n",
    "X_test = test_scaled[features]\n",
    "y_test = test_scaled['adj_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyswarms as ps\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-kitchen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-toner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(position):\n",
    "    \n",
    "    num_part, dummy = position.shape\n",
    "    \n",
    "    #print(position)\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_part):\n",
    "        \n",
    "    #print(position[i,0])\n",
    "    #print(position[i,1])\n",
    "\n",
    "\n",
    "        this_gamma = position[i,0]\n",
    "        this_sigma = position[i,1]\n",
    "\n",
    "        #breakpoint()\n",
    "\n",
    "\n",
    "        clfrbf=LSSVMRegression(\n",
    "        gamma=this_gamma,       #set the gamma-hyper parameter equal to 1\n",
    "        kernel='rbf', #use the linear kernel\n",
    "        sigma=this_sigma\n",
    "            )\n",
    "\n",
    "        ##print(clfrbf.get_params())\n",
    "\n",
    "        clfrbf.fit(X_train, y_train)\n",
    "\n",
    "        #y_train_pred = clfrbf.predict(X_train)\n",
    "\n",
    "        y_test_pred = clfrbf.predict(X_test)\n",
    "\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        \n",
    "        costs.append(mse_test)\n",
    "\n",
    "        #rmse_test = math.sqrt(mse_test)\n",
    "\n",
    "        #print('results for round: cost = {cost}, sigma = {sigma}, Gamma={gamma}'\n",
    "             # .format(cost = mse_test, sigma=this_sigma, gamma=this_gamma))\n",
    "\n",
    "    #mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "    #rmse_train = math.sqrt(mse_train)\n",
    "\n",
    "    #list(range(mse_f_train,rmse_f_train))\n",
    "    \n",
    "    \n",
    "    #print(costs)\n",
    "\n",
    "    \n",
    "    return costs\n",
    "    #Return a vector instead of single value. you can use the rmse_test and ignore rmse_train\n",
    "    \n",
    "    #svrRegressor = SVR(kernel='rbf', gamma = position[0].all(), C = position[1].all() )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wonder if reducing the # of features / lagging features increases training speed?\n",
    "# theoretical to\n",
    "# investigate numba library to do GPU calculations\n",
    "#parralelization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [0.01, 0.01]\n",
    "ub = [1000,1000]\n",
    "#mb = [100, 0.001]\n",
    "bounds = (lb,ub)\n",
    "\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=12, dimensions=2,options=options, bounds = bounds, ftol = .5)\n",
    "best_cost, opt_params = optimizer.optimize(fitness_function, iters=5, n_processes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-underwear",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(best_cost)\n",
    "print(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-nudist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfrbf=LSSVMRegression(\n",
    "        gamma=842.873436731312,       #set the gamma-hyper parameter equal to 1\n",
    "        kernel='rbf', #use the linear kernel\n",
    "        sigma=310.9203341185021\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfrbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-julian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clfrbf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-binding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clfrbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = clfrbf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_descale = test_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_descale['adj_close'] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inv_scaler = scaler.inverse_transform(df_to_descale)\n",
    "\n",
    "y_hat_descaled = pd.DataFrame(inv_scaler, columns = test_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat_descaled['adj_close'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-internship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test =mean_squared_error(y_test, y_hat)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-transmission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.plot(test_dates_list, y_hat_descaled['adj_close'])\n",
    "plt.plot(test_dates_list, test_close_vals)\n",
    "plt.legend(['pred','true'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-anxiety",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled['adj_close'] = y_hat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inv_scaler = scaler.inverse_transform(train_scaled)\n",
    "\n",
    "y_hat_train_descaled = pd.DataFrame(train_inv_scaler, columns = train_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-secretariat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.plot(train_dates_list[slow:], y_hat_train_descaled['adj_close'])\n",
    "plt.plot(train_dates_list, train_close_vals)\n",
    "plt.legend(['pred','true'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-wayne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-elite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
