{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "purple-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from yahoo_fin import stock_info as si\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import talib\n",
    "from talib import *\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators():\n",
    "        \n",
    "    upper_band, mid_band, lower_band = BBANDS(df['Adj Close'],timeperiod=really_fast, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    d_ema = DEMA(df['Adj Close'], timeperiod=really_fast)\n",
    "    E_M_A = EMA(df['Adj Close'], timeperiod=fast)\n",
    "    ht_trend = HT_TRENDLINE(df['Adj Close'])\n",
    "    kama = KAMA(df['Adj Close'], timeperiod=fast)\n",
    "    ma = MA(df['Adj Close'], timeperiod=fast, matype=0)\n",
    "    #mama, fama = MAMA(df['Adj Close'], fastlimit=really_fast, slowlimit=slow) < this gave me issues?\n",
    "    #mavp = MAVP(df['Adj Close'])\n",
    "    mid = MIDPOINT(df['Adj Close'], timeperiod=fast)\n",
    "    mid_price = MIDPRICE(df['High'], df['Low'], timeperiod=fast)\n",
    "    sar = SAR(df['High'], df['Low'], acceleration=.02, maximum=.2)\n",
    "    sarext = SAREXT(df['High'], df['Low'], startvalue=0, offsetonreverse=0, accelerationinitlong=.02, accelerationlong=.02, accelerationmaxlong=.2, accelerationinitshort=.02, accelerationshort=.02, accelerationmaxshort=.2)\n",
    "    sma = SMA(df['Adj Close'], timeperiod=slow)\n",
    "    tema = TEMA(df['Adj Close'], timeperiod=slow)\n",
    "    trima = TRIMA(df['Adj Close'], timeperiod=slow)\n",
    "    wma = WMA(df['Adj Close'], timeperiod=slow)\n",
    "\n",
    "    #this is some of the beginning stuff\n",
    "\n",
    "    O_B_V = OBV(df['Adj Close'], df['Volume'])\n",
    "    A_D_O_S_C = ADOSC(df['High'], df['Low'], df['Adj Close'], df['Volume'], fastperiod=fast, slowperiod=slow)\n",
    "    O_G_chaikin = AD(df['High'], df['Low'], df['Adj Close'], df['Volume'])\n",
    "    HT_DCper = HT_DCPERIOD(df['Adj Close'])\n",
    "    HT_DCphase = HT_DCPHASE(df['Adj Close'])\n",
    "    inphase, quad = HT_PHASOR(df['Adj Close'])\n",
    "    r_sin, leadsin = HT_SINE(df['Adj Close'])\n",
    "\n",
    "    #volatility\n",
    "    atr = ATR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "    natr = NATR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "    t_range = TRANGE(df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #below here are momentum ind\n",
    "\n",
    "    adx = ADX(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    adxr = ADXR(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    apo = APO(df['Adj Close'], fastperiod=really_fast, slowperiod=fast, matype=0)\n",
    "    aroon_d, aroon_u = AROON(df['High'], df['Low'], timeperiod=fast)\n",
    "    aroon_osc = AROONOSC(df['High'], df['Low'], timeperiod=fast)\n",
    "    bop = BOP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    cci = CCI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    cmo = CMO(df['Adj Close'], timeperiod=fast)\n",
    "    dx = DX(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    macd, macdsig, macdhist = MACD(df['Adj Close'], fastperiod=fast, slowperiod=slow, signalperiod=really_fast)\n",
    "    macdex, macdexsig, macdexhist = MACDEXT(df['Adj Close'], fastperiod=fast, fastmatype=0, slowperiod=slow, slowmatype=0, signalperiod=really_fast, signalmatype=0)\n",
    "    macdfixd, macdfixdsig, macdfixdhist = MACDFIX(df['Adj Close'], signalperiod=really_fast)\n",
    "    # more momo's\n",
    "\n",
    "    mfi = MFI(df['High'], df['Low'], df['Adj Close'],df['Volume'],timeperiod=fast)\n",
    "    min_di = MINUS_DI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    min_dm = MINUS_DM(df['High'], df['Low'], timeperiod=fast)\n",
    "    momo = MOM(df['Adj Close'], timeperiod=really_fast)\n",
    "    plus_di = PLUS_DI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    plus_dm = PLUS_DM(df['High'], df['Low'], timeperiod=fast)\n",
    "    ppo = PPO(df['Adj Close'], fastperiod=really_fast, slowperiod=fast, matype=0)\n",
    "    roc = ROC(df['Adj Close'], timeperiod=fast)\n",
    "    rocp = ROCP(df['Adj Close'], timeperiod=fast)\n",
    "    rocr = ROCR(df['Adj Close'], timeperiod=fast)\n",
    "    rocr_hund = ROCR100(df['Adj Close'], timeperiod = fast)\n",
    "    rsi_fastk, rsi_fastd = STOCHRSI(df['Adj Close'], timeperiod=fast, fastk_period=slow, fastd_period=really_fast, fastd_matype=0)\n",
    "    trix = TRIX(df['Adj Close'], timeperiod=slow)\n",
    "    ult_osc = ULTOSC(df['High'], df['Low'], df['Adj Close'], timeperiod1=really_fast, timeperiod2=fast, timeperiod3=slow)\n",
    "\n",
    "\n",
    "    #old some of the first added\n",
    "    R_S_I = RSI(df['Adj Close'], timeperiod=slow)\n",
    "    slowk, slowd = STOCH(df['High'], df['Low'], df['Adj Close'], fastk_period=fast, slowk_period=slow, slowk_matype=0, slowd_period=slow, slowd_matype=0)\n",
    "    fastk, fastd = STOCHF(df['High'], df['Low'], df['Adj Close'], fastk_period=fast, fastd_period=really_fast, fastd_matype=0)\n",
    "\n",
    "    real = WILLR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "\n",
    "    # below are the TA indicators\n",
    "\n",
    "    two_crows = CDL2CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_crows = CDL3BLACKCROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_inside = CDL3INSIDE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_line = CDL3LINESTRIKE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_out = CDL3OUTSIDE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_stars = CDL3STARSINSOUTH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_soldier = CDL3WHITESOLDIERS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    baby = CDLABANDONEDBABY(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    adv = CDLADVANCEBLOCK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    belt_hold = CDLBELTHOLD(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    breakaway = CDLBREAKAWAY(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    closingmara = CDLCLOSINGMARUBOZU(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    baby_swallow = CDLCONCEALBABYSWALL(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    counter = CDLCOUNTERATTACK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    dark_cloud = CDLDARKCLOUDCOVER(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    doji = CDLDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    doji_star = CDLDOJISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    dragon_doji = CDLDRAGONFLYDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    engulf = CDLENGULFING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    evening_star = CDLEVENINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    gapside = CDLGAPSIDESIDEWHITE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    gravestone = CDLGRAVESTONEDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hammer = CDLHAMMER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hang_man = CDLHANGINGMAN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    harami = CDLHARAMI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    harami_cross = CDLHARAMICROSS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    high_wave = CDLHIGHWAVE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hikkake = CDLHIKKAKE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hikkake_mod = CDLHIKKAKEMOD(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    pidgeon = CDLHOMINGPIGEON(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    id_three_crows = CDLIDENTICAL3CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    in_neck = CDLINNECK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    inv_hammer = CDLINVERTEDHAMMER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    kicking = CDLKICKING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    kicking_len = CDLKICKINGBYLENGTH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    ladder_bot = CDLLADDERBOTTOM(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    doji_long = CDLLONGLEGGEDDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    long_line = CDLLONGLINE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    marabozu = CDLMARUBOZU(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    match_glow = CDLMATCHINGLOW(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    mat_hold = CDLMATHOLD(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    morning_doji = CDLMORNINGDOJISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    morning_star = CDLMORNINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    on_neck = CDLONNECK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    pierce = CDLPIERCING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    rickshaw = CDLRICKSHAWMAN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    rise_fall = CDLRISEFALL3METHODS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    sep_line = CDLSEPARATINGLINES(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    shooting_star = CDLSHOOTINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    sl_candle = CDLSHORTLINE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    spin_top = CDLSPINNINGTOP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    stalled = CDLSTALLEDPATTERN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    stick_sand = CDLSTICKSANDWICH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    takuri = CDLTAKURI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    tasuki_gap = CDLTASUKIGAP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    thrust = CDLTHRUSTING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    tristar = CDLTRISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_river = CDLUNIQUE3RIVER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    ud_two_gap = CDLUPSIDEGAP2CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    down_three_gap = CDLXSIDEGAP3METHODS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #76 vars\n",
    "\n",
    "    #are_all_zero = (test_TA == 0).all()\n",
    "    #true if all values are 0\n",
    "    #false if contain a non 0'''\n",
    "\n",
    "    df.drop(['Close'], axis =1, inplace = True)\n",
    "\n",
    "    df['upper_band'] = upper_band\n",
    "    df['lower_band'] = lower_band\n",
    "    df['mid_band'] = mid_band\n",
    "    df['d_ema'] = d_ema\n",
    "    df['ht_trend'] = ht_trend\n",
    "    df['kama'] = kama\n",
    "    df['ma'] = ma\n",
    "    #df['mama'] = mama\n",
    "    df['mid'] = mid\n",
    "    df['mid_price'] = mid_price\n",
    "\n",
    "    df['sar'] = sar\n",
    "    df['sarext'] = sarext\n",
    "    df['sma'] = sma\n",
    "    df['tema'] = tema\n",
    "    df['trima'] = trima\n",
    "    df['wma'] = wma\n",
    "    #df['fama'] = fama\n",
    "\n",
    "    df['EMA'] = E_M_A\n",
    "    df['SlowK'] = slowk\n",
    "    df['SlowD'] = slowd\n",
    "    df['R_S_I'] = R_S_I\n",
    "    df['FastK'] = fastk\n",
    "    df['FastD'] = fastd\n",
    "    df['WilliamsR'] = real\n",
    "\n",
    "    df['atr'] = atr\n",
    "    df['natr'] = natr\n",
    "    df['t_range'] = t_range\n",
    "\n",
    "\n",
    "    #df['na_tr'] = natr\n",
    "\n",
    "    df['OBV'] = O_B_V\n",
    "    df['ADOSC'] = A_D_O_S_C\n",
    "    df['ogchaikin'] = O_G_chaikin\n",
    "    df['HTDCperiod'] = HT_DCper\n",
    "    df['HTDCphase'] = HT_DCphase\n",
    "    df['inphase'] = inphase\n",
    "    df['quad'] = quad\n",
    "    df['rsin'] = r_sin\n",
    "    df['leadsin'] = leadsin\n",
    "\n",
    "    df['mfi'] = mfi\n",
    "    df['min_di'] = min_di\n",
    "    df['min_dm'] = min_dm\n",
    "    df['momo'] = momo\n",
    "    df['plus_di'] = plus_di\n",
    "    df['plus_dm'] = plus_dm\n",
    "    df['ppo'] = ppo\n",
    "    df['roc'] = roc\n",
    "    df['rocp'] = rocp\n",
    "\n",
    "    df['rocr'] = rocr\n",
    "    df['rocr_hund'] = rocr_hund\n",
    "    df['rsi_fastk'] = rsi_fastk\n",
    "    df['rsi_fastd'] = rsi_fastd\n",
    "    df['trix'] = trix\n",
    "    df['ult_osc'] = ult_osc\n",
    "\n",
    "    df['adx'] = adx\n",
    "    df['adxr'] = adxr\n",
    "    df['apo'] = apo\n",
    "    df['aroon_d'] = aroon_d\n",
    "    df['aroon_u'] = aroon_u\n",
    "    df['aroon_osc'] = aroon_osc\n",
    "    df['bop'] = bop\n",
    "    df['cci'] = cci\n",
    "    df['cmo'] = cmo\n",
    "\n",
    "    df['dx'] = dx\n",
    "    df['macd'] = macd\n",
    "    df['macdsig'] = macdsig\n",
    "    df['macdhist'] = macdhist\n",
    "    df['macdex'] = macdex\n",
    "    df['macdexsig'] = macdexsig\n",
    "    df['macdexhist'] = macdexhist\n",
    "    df['macdfixd'] = macdfixd\n",
    "    df['macdfixdsig'] = macdfixdsig\n",
    "    df['macdfixdhist'] = macdfixdhist\n",
    "\n",
    "    df['two_crows'] = two_crows\n",
    "    df['three_crows'] = three_crows\n",
    "    df['three_inside'] = three_inside\n",
    "    df['three_line'] = three_line\n",
    "    df['three_out'] = three_out\n",
    "    df['three_stars'] = three_stars\n",
    "    df['three_soldier'] = three_soldier\n",
    "    df['baby'] = baby\n",
    "    df['adv'] = adv\n",
    "    df['belt_hold'] = belt_hold\n",
    "    df['breakaway'] = breakaway\n",
    "    df['closingmara'] = closingmara\n",
    "    df['baby_swallow'] = belt_hold\n",
    "\n",
    "    df['counter'] = counter\n",
    "    df['dark_cloud'] = dark_cloud\n",
    "    df['doji'] = doji\n",
    "    df['doji_star'] = doji_star\n",
    "    df['dragon_doji'] = dragon_doji\n",
    "    df['engulf'] = engulf\n",
    "    df['evening_star'] = evening_star\n",
    "    df['gapside'] = gapside\n",
    "    df['gravestone'] = gravestone\n",
    "    df['hammer'] = hammer\n",
    "    df['hang_man'] = hang_man\n",
    "    df['harami'] = harami\n",
    "    df['harami_cross'] = harami_cross\n",
    "\n",
    "    df['high_wave'] = high_wave\n",
    "    df['hikkake'] = hikkake\n",
    "    df['hikkake_mod'] = hikkake_mod\n",
    "    df['pidgeon'] = pidgeon\n",
    "    df['id_three_crows'] = id_three_crows\n",
    "    df['in_neck'] = in_neck\n",
    "    df['inv_hammer'] = inv_hammer\n",
    "    df['kicking'] = kicking\n",
    "    df['kicking_len'] = kicking_len\n",
    "    df['ladder_bot'] = ladder_bot\n",
    "    df['doji_long'] = doji_long\n",
    "    df['long_line'] = long_line\n",
    "    df['marabozu'] = marabozu\n",
    "                                                    # this is  a comment\n",
    "    df['match_glow'] = match_glow\n",
    "    df['mat_hold'] = mat_hold\n",
    "    df['morning_doji'] = morning_doji\n",
    "    df['morning_star'] = morning_star\n",
    "    df['on_neck'] = on_neck\n",
    "    df['pierce'] = pierce\n",
    "    df['rickshaw'] = rickshaw\n",
    "    df['rise_fall'] = rise_fall\n",
    "    df['sep_line'] = sep_line\n",
    "    df['shooting_star'] = shooting_star\n",
    "    df['sl_candle'] = sl_candle\n",
    "    df['spin_top'] = spin_top\n",
    "    df['stalled'] = stalled\n",
    "\n",
    "    df['stick_sand'] = stick_sand\n",
    "    df['takuri'] = takuri\n",
    "    df['tasuki_gap'] = tasuki_gap\n",
    "    df['thrust'] = thrust\n",
    "    df['tristar'] = tristar\n",
    "    df['three_river'] = three_river\n",
    "    df['ud_two_gap'] = ud_two_gap\n",
    "    df['down_three_gap'] = down_three_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suspected-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag(num_lag_cols, this_df):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    lag_cols = ['ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc','adj_close', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line', 'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows','in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                'mid_band','d_ema','ht_trend','kama','ma','mid','mid_price','sar','sarext','sma','tema','trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix','ult_osc', 'atr','natr','t_range'\n",
    "                ]\n",
    "\n",
    "    shift_range = [x+1 for x in range(num_lag_cols)]\n",
    "\n",
    "    for shift in shift_range:\n",
    "        train_shift = this_df[merging_keys + lag_cols].copy()\n",
    "\n",
    "        # E.g. order_day of 0 becomes 1, for shift = 1.\n",
    "        # So when this is merged with order_day of 1 in df, this will represent lag of 1.\n",
    "        train_shift['order_day'] = train_shift['order_day'] + shift\n",
    "\n",
    "        foo = lambda x: '{}_lag_{}'.format(x, shift) if x in lag_cols else x\n",
    "        train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "        this_df = pd.merge(this_df, train_shift, on=merging_keys, how='left') #.fillna(0)\n",
    "\n",
    "    del train_shift\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "\n",
    "    print(f\"completed lagging in {tic_toc:0.4f} min\")\n",
    "    \n",
    "\n",
    "    return this_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impossible-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, window_size):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    '''df.loc[df['adj_close'] >= df['adj_close'].rolling(window_size).max(), 'test_labels'] = 0\n",
    "    df.loc[df['adj_close'] <= df['adj_close'].rolling(window_size).min(), 'test_labels'] = 1'''\n",
    "    # interesting use of quantile\n",
    "    # could also attempt to implement STD dev here, though choosing quantiles / std dev should produce the same result\n",
    "    # might try to use a larger window size to capture more of the true \"dips\"\n",
    "    \n",
    "    #indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n",
    "\n",
    "    #df.rolling(window=indexer, min_periods=1).sum()\n",
    "    \n",
    "    df.loc[df['adj_close'] >= df['adj_close'].rolling(window_size, center=True).quantile(.9, interpolation='linear'), 'labels'] = 0 # sell\n",
    "    \n",
    "    df.loc[df['adj_close'] <= df['adj_close'].rolling(window_size, center=True).quantile(.1, interpolation='linear'), 'labels'] = 1 #buy\n",
    "    df['labels'].fillna(2, inplace = True)\n",
    "    \n",
    "    \n",
    "    #list_test_labels = df['test_labels']\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "    \n",
    "    #BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "    print(f\"completed labels in {tic_toc:0.4f} min\")\n",
    "    \n",
    "    #return list_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "practical-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scale(num_interval_lag):\n",
    "\n",
    "    cols_to_scale = ['ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                    'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line', 'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                    'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                    'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows','in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                    'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                    'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                    'mid_band','d_ema','ht_trend','kama','ma','mid','mid_price','sar','sarext','sma','tema','trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                    'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                    'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix','ult_osc', 'atr','natr','t_range'\n",
    "                    ]\n",
    "\n",
    "    for i in range(1,num_interval_lag+1):\n",
    "        cols_to_scale.append(\"ema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"r_s_i_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"fastk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"fastd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"williamsr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"volume_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"range_hl_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"range_oc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adj_close_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"upper_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"lower_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"d_ema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ht_trend_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kama_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ma_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_price_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sar_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sarext_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sma_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"trima_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"wma_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"atr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"natr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"t_range_lag_\"+str(i))\n",
    "\n",
    "        #momentum indicator lag cols\n",
    "\n",
    "        cols_to_scale.append(\"adx_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adxr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"apo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_d_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_u_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_osc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"bop_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"cci_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"cmo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"dx_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdhist_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdex_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"mfi_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"min_di_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"min_dm_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"momo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"plus_di_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"plus_dm_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ppo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"roc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocp_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocr_hund_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsi_fastk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsi_fastd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"trix_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ult_osc_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"macdexsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdexhist_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixdsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixdhist_lag_\"+str(i))\n",
    "\n",
    "\n",
    "        #cols_to_scale.append(\"mama_lag_\"+str(i))\n",
    "        #cols_to_scale.append(\"NATR_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"obv_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"adosc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ogchaikin_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"htdcperiod_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"htdcphase_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"inphase_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"quad_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsin_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"leadsin_lag_\"+str(i))\n",
    "        #cols_to_scale.append(\"fama_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"two_crows_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"three_crows_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_inside_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_out_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_stars_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_soldier_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"baby_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adv_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"belt_hold_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"breakaway_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"closingmara_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"baby_swallow_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"counter_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"dark_cloud_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"dragon_doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"engulf_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"evening_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"gapside_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"gravestone_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hammer_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hang_man_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"harami_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"harami_cross_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"high_wave_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"hikkake_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hikkake_mod_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"pidgeon_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"id_three_crows_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"in_neck_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"inv_hammer_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kicking_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kicking_len_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ladder_bot_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_long_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"long_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"marabozu_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"match_glow_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"mat_hold_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"morning_doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"morning_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"on_neck_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"pierce_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rickshaw_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rise_fall_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sep_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"shooting_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sl_candle_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"spin_top_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"stalled_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"stick_sand_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"takuri_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tasuki_gap_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"thrust_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tristar_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_river_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ud_two_gap_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"down_three_gap_lag_\"+str(i))\n",
    "\n",
    "    return cols_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-burner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "legitimate-orleans",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "completed lagging in 0.1485 min\n"
     ]
    }
   ],
   "source": [
    "stock = 'NGG'\n",
    "\n",
    "\n",
    "# You will need to drop the non lagged columns > they are a data leak to the current adj_close\n",
    "\n",
    "\n",
    "start_date = datetime.datetime.now() - datetime.timedelta(days=59)\n",
    "\n",
    "end_date = datetime.datetime.now()\n",
    "\n",
    "df = pdr.get_data_yahoo(stock, start=start_date, end=end_date, interval = \"2m\", prepost=True)\n",
    "\n",
    "#df = pdr.get_data_yahoo(stock, period = \"max\", interval = \"1d\", prepost = True)\n",
    "\n",
    "#df.index = df.index.tz_localize(None)\n",
    "\n",
    "'''#2 min ticker\n",
    "# 30 intervals = 1 hour << OLD\n",
    "# 195 intervals = trading day'''\n",
    "                                            # there are more intervals that we can use / change\n",
    "really_fast = 30\n",
    "fast = 60\n",
    "slow = 90\n",
    "\n",
    "add_indicators()\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "# Change all column headings to be lower case, and remove spacing\n",
    "df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n",
    "\n",
    "# Get difference between high and low of each day\n",
    "df['range_hl'] = df['high'] - df['low']\n",
    "df.drop(['high', 'low'], axis=1, inplace=True)\n",
    "# Get difference between open and close of each day\n",
    "df['range_oc'] = df['open'] - df['adj_close']\n",
    "df.drop(['open'], axis=1, inplace=True)\n",
    "# Add a column 'order_day' to indicate the order of the rows by date\n",
    "df['order_day'] = [x for x in list(range(len(df)))]\n",
    "# merging_keys\n",
    "merging_keys = ['order_day']\n",
    "\n",
    "num_interval_lag = 30\n",
    "\n",
    "df = add_lag(num_interval_lag, df)\n",
    "\n",
    "#df['adj_close'] = df['adj_close'].shift(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "permanent-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "quick-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "upper-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#df.tail(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "processed-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed labels in 0.0002 min\n"
     ]
    }
   ],
   "source": [
    "#add_labels(df)\n",
    "#1 day - 195, 2 = 390, 3 = 585, 4 = 780, 5 = 975\n",
    "#6 = 1170, 7 = 1365, 8 = 1560, 9 = 1755, 10 = 1950\n",
    "window_size = 585\n",
    "add_labels(df, window_size)\n",
    "\n",
    "\n",
    "#print(df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "capable-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    5531\n",
       "0.0     447\n",
       "1.0     441\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vals = df['labels'].value_counts()\n",
    "df['labels'].value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "automotive-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_buys = label_vals[1]\n",
    "num_sells = label_vals[0]\n",
    "num_holds = label_vals[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "expressed-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "least_vals = min(num_buys, num_sells, num_holds)\n",
    "#print(least_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "important-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_factor = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "willing-soviet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9865771812080537\n",
      "0.07973241728439703\n"
     ]
    }
   ],
   "source": [
    "weight_buys = imp_factor * (least_vals / num_buys)\n",
    "weight_sells = imp_factor * (least_vals / num_sells)\n",
    "weight_holds = least_vals / num_holds\n",
    "print(weight_buys)\n",
    "print(weight_sells)\n",
    "print(weight_holds)\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "combined-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list = df.index[df['labels'] == 1].tolist()\n",
    "sell_list = df.index[df['labels'] == 0].tolist()\n",
    "hold_list = df.index[df['labels'] == 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "theoretical-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[buy_list, 'weights'] = weight_buys\n",
    "df.loc[sell_list, 'weights'] = weight_sells\n",
    "df.loc[hold_list, 'weights'] = weight_holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-profile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "electronic-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['weights'].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-influence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "periodic-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rem = ['ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc','adj_close', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line', 'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows','in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                'mid_band','d_ema','ht_trend','kama','ma','mid','mid_price','sar','sarext','sma','tema','trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix','ult_osc', 'atr','natr','t_range', 'weights'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "spiritual-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_vals_list = df['adj_close']\n",
    "weights_list = df['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "velvet-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols_to_rem, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "available-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dimensional-destination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3963"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "australian-console",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3963"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cross-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "governing-heath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6418    2.0\n",
      "Name: labels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "num_test = int(.2*len(df))\n",
    "num_train = len(df) - num_test\n",
    "\n",
    "\n",
    "print(df['labels'].iloc[[-1]])\n",
    "\n",
    "#train_close_vals = close_vals_list[:num_train]\n",
    "test_close_vals = close_vals_list[num_train:]\n",
    "\n",
    "#test_dates_list = test['date']\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "removable-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates_list = df['datetime'].tail(num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "billion-summit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "lesser-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "revolutionary-operator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    5531\n",
       "0.0     447\n",
       "1.0     441\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "african-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dimensional-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = add_scale(num_interval_lag)\n",
    "\n",
    "#cols_to_scale.remove(cols_to_rem)\n",
    "\n",
    "# Do scaling for train set\n",
    "# Here we only scale the train dataset, and not the entire dataset to prevent information leak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "differential-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "steady-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in cols_to_rem:\n",
    "\n",
    "    if element in cols_to_scale:\n",
    "\n",
    "        cols_to_scale.remove(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "sublime-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3960"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "after-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[slow:]\n",
    "weights_list = weights_list[slow:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-campbell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "outstanding-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = df[cols_to_scale]\n",
    "all_y = df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size=0.2, shuffle = False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle = False) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "#scaling test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "conditional-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(X_train)\n",
    "val_len = len(X_val)\n",
    "test_len = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "alive-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights = weights_list[:train_len]\n",
    "val_weights = weights_list[train_len:train_len + val_len]\n",
    "test_weights = weights_list[train_len + val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "generic-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "useful-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1154\n",
       "1.0      69\n",
       "0.0      43\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "occasional-watershed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266\n",
      "1266\n"
     ]
    }
   ],
   "source": [
    "print(test_len)\n",
    "print(len(test_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "charming-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train, label = y_train, weight = train_weights)\n",
    "d_val = xgb.DMatrix(X_val, label = y_val, weight = val_weights)\n",
    "d_test = xgb.DMatrix(X_test, label = y_test, weight = test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "greater-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1032\n",
       "0.0     137\n",
       "1.0      97\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val_frame = pd.DataFrame(val_weights)\n",
    "#BUY => 1, SELL => 0, HOLD => 2\n",
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "naughty-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "from typing import Tuple\n",
    "\n",
    "def f_2_score(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "    ''' Root mean squared log error metric.'''\n",
    "    y = dtrain.get_label()\n",
    "    \n",
    "    inter_vals = pd.DataFrame(y)\n",
    "    vals_all = inter_vals.value_counts()\n",
    "    \n",
    "    #BUY => 1, SELL => 0, HOLD => 2\n",
    "    \n",
    "    inter_num_buys = vals_all[1]\n",
    "    inter_num_sells = vals_all[0]\n",
    "    inter_num_holds = vals_all[2]\n",
    "    \n",
    "    least_vals = min(inter_num_buys, inter_num_sells, inter_num_holds)\n",
    "    \n",
    "    imp_factor = 1.5\n",
    "    \n",
    "    inter_weight_buys = imp_factor * (least_vals / inter_num_buys)\n",
    "    inter_weight_sells = imp_factor * (least_vals / inter_num_sells)\n",
    "    inter_weight_holds = least_vals / inter_num_holds\n",
    "    \n",
    "    #print(inter_weight_holds)\n",
    "    \n",
    "    #predt[predt < -1] = -1 + 1e-6\n",
    "\n",
    "    #print(len(predt))\n",
    "    #print(predt.shape)\n",
    "    \n",
    "    y_pred = [None] * len(predt)\n",
    "    inter_weights = [None] * len(predt)\n",
    "    for x in range(len(predt)):\n",
    "        if predt[x,0] > 0.5:\n",
    "            y_pred[x] = 0\n",
    "            inter_weights[x] = inter_weight_sells\n",
    "        elif predt[x,1] > 0.5:\n",
    "            y_pred[x] = 1\n",
    "            inter_weights[x] = inter_weight_buys\n",
    "        else:\n",
    "            y_pred[x] = 2\n",
    "            inter_weights[x] = inter_weight_holds\n",
    "            \n",
    "    breakpoint\n",
    "    #print(y_pred)\n",
    "    \n",
    "    f_beta_return = fbeta_score(y, y_pred, beta=2, average = 'weighted', sample_weight = inter_weights)\n",
    "    \n",
    "    \n",
    "    return 'F2_score', float(f_beta_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-finish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-phone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "comic-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(d_val, 'val')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "statistical-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "params = {'tree_method': 'gpu_hist',\n",
    "            'gpu_id': 0,\n",
    "            #'disable_default_eval_metric':True,\n",
    "            'max_depth':10,\n",
    "            'learning_rate':0.1,\n",
    "            'eval_metric': ['merror','mlogloss'],\n",
    "            'objective': 'multi:softmax',\n",
    "            'min_child_weight':1,\n",
    "            'subsample':1,\n",
    "            'num_class': 3,\n",
    "            'gamma':0.1,\n",
    "            'verbosity': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aboriginal-bathroom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-merror:0.73641\tval-mlogloss:1.10783\n",
      "[1]\tval-merror:0.73424\tval-mlogloss:1.11964\n",
      "[2]\tval-merror:0.73933\tval-mlogloss:1.13878\n",
      "[3]\tval-merror:0.73857\tval-mlogloss:1.16212\n",
      "[4]\tval-merror:0.73832\tval-mlogloss:1.19136\n",
      "[5]\tval-merror:0.73832\tval-mlogloss:1.22052\n",
      "[6]\tval-merror:0.73832\tval-mlogloss:1.25062\n",
      "[7]\tval-merror:0.73832\tval-mlogloss:1.28849\n",
      "[8]\tval-merror:0.73832\tval-mlogloss:1.32055\n",
      "[9]\tval-merror:0.73832\tval-mlogloss:1.35666\n",
      "[10]\tval-merror:0.73832\tval-mlogloss:1.38649\n",
      "[11]\tval-merror:0.73832\tval-mlogloss:1.41848\n",
      "[12]\tval-merror:0.73832\tval-mlogloss:1.44470\n",
      "[13]\tval-merror:0.73832\tval-mlogloss:1.48163\n",
      "[14]\tval-merror:0.73832\tval-mlogloss:1.51690\n",
      "[15]\tval-merror:0.73832\tval-mlogloss:1.55526\n",
      "[16]\tval-merror:0.73832\tval-mlogloss:1.59197\n",
      "[17]\tval-merror:0.73832\tval-mlogloss:1.63579\n",
      "[18]\tval-merror:0.73832\tval-mlogloss:1.67564\n",
      "[19]\tval-merror:0.73832\tval-mlogloss:1.72290\n",
      "[20]\tval-merror:0.73832\tval-mlogloss:1.76858\n",
      "[21]\tval-merror:0.73832\tval-mlogloss:1.80704\n",
      "[22]\tval-merror:0.73832\tval-mlogloss:1.84632\n",
      "[23]\tval-merror:0.73832\tval-mlogloss:1.89170\n",
      "[24]\tval-merror:0.73832\tval-mlogloss:1.94019\n",
      "[25]\tval-merror:0.73832\tval-mlogloss:1.98455\n",
      "[26]\tval-merror:0.73832\tval-mlogloss:2.02451\n",
      "[27]\tval-merror:0.73832\tval-mlogloss:2.05847\n",
      "[28]\tval-merror:0.73832\tval-mlogloss:2.09726\n",
      "[29]\tval-merror:0.73832\tval-mlogloss:2.13129\n",
      "[30]\tval-merror:0.73832\tval-mlogloss:2.16782\n",
      "[31]\tval-merror:0.73832\tval-mlogloss:2.20137\n",
      "[32]\tval-merror:0.73832\tval-mlogloss:2.23407\n",
      "[33]\tval-merror:0.73832\tval-mlogloss:2.26948\n",
      "[34]\tval-merror:0.73832\tval-mlogloss:2.29930\n",
      "[35]\tval-merror:0.73832\tval-mlogloss:2.33467\n",
      "[36]\tval-merror:0.73832\tval-mlogloss:2.36536\n",
      "[37]\tval-merror:0.73832\tval-mlogloss:2.39720\n",
      "[38]\tval-merror:0.73832\tval-mlogloss:2.43370\n",
      "[39]\tval-merror:0.73832\tval-mlogloss:2.46870\n",
      "[40]\tval-merror:0.73832\tval-mlogloss:2.50084\n",
      "[41]\tval-merror:0.73832\tval-mlogloss:2.53744\n",
      "[42]\tval-merror:0.73832\tval-mlogloss:2.54313\n",
      "[43]\tval-merror:0.73832\tval-mlogloss:2.56452\n",
      "[44]\tval-merror:0.73832\tval-mlogloss:2.58662\n",
      "[45]\tval-merror:0.73832\tval-mlogloss:2.59860\n",
      "[46]\tval-merror:0.73832\tval-mlogloss:2.61246\n",
      "[47]\tval-merror:0.73832\tval-mlogloss:2.64278\n",
      "[48]\tval-merror:0.73832\tval-mlogloss:2.66686\n",
      "[49]\tval-merror:0.73832\tval-mlogloss:2.69580\n"
     ]
    }
   ],
   "source": [
    "#num_round = 1000\n",
    "bst = xgb.train(params,\n",
    "                d_train,\n",
    "                num_boost_round = 1000,\n",
    "                #feval = f_2_score,\n",
    "                evals = eval_set,\n",
    "                evals_result = evals_result,\n",
    "                early_stopping_rounds = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "documentary-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "placed-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "loaded-lottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1266\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "olympic-safety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1154\n",
       "1.0      69\n",
       "0.0      43\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-converter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(evals_result['val']['merror'])\n",
    "x_axis = range(0, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(x_axis, evals_result['train']['mlogloss'], label='Train')\n",
    "ax.plot(x_axis, evals_result['val']['mlogloss'], label='Val')\n",
    "ax.legend()\n",
    "plt.ylabel('logloss')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.title('XGBoost logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(x_axis, evals_result['train']['merror'], label='Train')\n",
    "ax.plot(x_axis, evals_result['val']['merror'], label='Val')\n",
    "ax.legend()\n",
    "plt.ylabel('merror')\n",
    "plt.title('XGBoost merror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "xgb.plot_importance(bst, max_num_features = 50)\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "xgb.plot_tree(bst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = bst.get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keys = sorted(feature_dict, key=feature_dict.get, reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-married",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "target_names = ['Sell', 'Buy', 'Hold']\n",
    "print(classification_report_imbalanced(y_test.values, preds_df.values, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test.values.tolist(), preds_df.values.tolist())\n",
    "conf_mat_norm = confusion_matrix(y_test.values.tolist(), preds_df.values.tolist(), normalize = 'true')\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(conf_mat_norm, display_labels = target_names)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-payroll",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_df.values[-1])\n",
    "#last class label\n",
    "#plt.ylabel('BUY => 1, SELL => 0, HOLD => 2')\n",
    "test_dates_list[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list_markers = preds_df.index[preds_df[0]==1].tolist()\n",
    "sell_list_markers = preds_df.index[preds_df[0]==0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(buy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list_true_markers = preds_df.index[y_test.values==1].tolist()\n",
    "sell_list_true_markers = preds_df.index[y_test.values==0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_list_true_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-packet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.plot(test_dates_list, test_close_vals)\n",
    "plt.plot(test_dates_list, test_close_vals, 'g^', markevery=buy_list_markers)\n",
    "plt.plot(test_dates_list, test_close_vals, 'rv', markevery=sell_list_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.plot(test_dates_list, test_close_vals)\n",
    "plt.plot(test_dates_list, test_close_vals, 'g^', markevery = buy_list_true_markers)\n",
    "plt.plot(test_dates_list, test_close_vals, 'rv', markevery = sell_list_true_markers[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-barrel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
