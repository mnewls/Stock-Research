{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "purple-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from yahoo_fin import stock_info as si\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import talib\n",
    "from talib import *\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-locking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators():\n",
    "        \n",
    "    upper_band, mid_band, lower_band = BBANDS(df['Adj Close'],timeperiod=slow, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    \n",
    "    upper_band_nine, mid_band_nine, lower_band_nine = BBANDS(df['Adj Close'],timeperiod=fast,\n",
    "                                                             nbdevup=1.645, nbdevdn=1.645, matype=0)\n",
    "    \n",
    "    upper_band_one, mid_band_one, lower_band_one = BBANDS(df['Adj Close'],timeperiod=really_fast,\n",
    "                                                             nbdevup=1, nbdevdn=1, matype=0)\n",
    "    \n",
    "    upper_band_slow, mid_band_slow, lower_band_slow = BBANDS(df['Adj Close'],timeperiod=slow,\n",
    "                                                             nbdevup=1.645, nbdevdn=1.645, matype=0)\n",
    "    \n",
    "    d_ema = DEMA(df['Adj Close'], timeperiod=really_fast)\n",
    "    E_M_A = EMA(df['Adj Close'], timeperiod=fast)\n",
    "    ht_trend = HT_TRENDLINE(df['Adj Close'])\n",
    "    kama = KAMA(df['Adj Close'], timeperiod=fast)\n",
    "    ma_fast = MA(df['Adj Close'], timeperiod=fast, matype=0)\n",
    "    ma_really_fast = MA(df['Adj Close'], timeperiod=really_fast, matype=0)\n",
    "    ma_slow = MA(df['Adj Close'], timeperiod=slow, matype=0)\n",
    "    #mama, fama = MAMA(df['Adj Close'], fastlimit=really_fast, slowlimit=slow) < this gave me issues?\n",
    "    #mavp = MAVP(df['Adj Close'])\n",
    "    mid = MIDPOINT(df['Adj Close'], timeperiod=fast)\n",
    "    mid_price = MIDPRICE(df['High'], df['Low'], timeperiod=fast)\n",
    "    sar = SAR(df['High'], df['Low'], acceleration=.02, maximum=.2)\n",
    "    sarext = SAREXT(df['High'], df['Low'], startvalue=0, offsetonreverse=0, accelerationinitlong=.02, accelerationlong=.02, accelerationmaxlong=.2, accelerationinitshort=.02, accelerationshort=.02, accelerationmaxshort=.2)\n",
    "    sma = SMA(df['Adj Close'], timeperiod=slow)\n",
    "    tema = TEMA(df['Adj Close'], timeperiod=slow)\n",
    "    trima = TRIMA(df['Adj Close'], timeperiod=slow)\n",
    "    wma = WMA(df['Adj Close'], timeperiod=slow)\n",
    "\n",
    "    #this is some of the beginning stuff\n",
    "\n",
    "    O_B_V = OBV(df['Adj Close'], df['Volume'])\n",
    "    A_D_O_S_C = ADOSC(df['High'], df['Low'], df['Adj Close'], df['Volume'], fastperiod=fast, slowperiod=slow)\n",
    "    O_G_chaikin = AD(df['High'], df['Low'], df['Adj Close'], df['Volume'])\n",
    "    HT_DCper = HT_DCPERIOD(df['Adj Close'])\n",
    "    HT_DCphase = HT_DCPHASE(df['Adj Close'])\n",
    "    inphase, quad = HT_PHASOR(df['Adj Close'])\n",
    "    r_sin, leadsin = HT_SINE(df['Adj Close'])\n",
    "\n",
    "    #volatility\n",
    "    atr = ATR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "    natr = NATR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "    t_range = TRANGE(df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #below here are momentum ind\n",
    "\n",
    "    adx = ADX(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    adxr = ADXR(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    apo = APO(df['Adj Close'], fastperiod=really_fast, slowperiod=fast, matype=0)\n",
    "    aroon_d, aroon_u = AROON(df['High'], df['Low'], timeperiod=fast)\n",
    "    aroon_osc = AROONOSC(df['High'], df['Low'], timeperiod=fast)\n",
    "    bop = BOP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    cci = CCI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    cmo = CMO(df['Adj Close'], timeperiod=fast)\n",
    "    dx = DX(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    macd, macdsig, macdhist = MACD(df['Adj Close'], fastperiod=fast, slowperiod=slow, signalperiod=really_fast)\n",
    "    macdex, macdexsig, macdexhist = MACDEXT(df['Adj Close'], fastperiod=fast, fastmatype=0, slowperiod=slow, slowmatype=0, signalperiod=really_fast, signalmatype=0)\n",
    "    macdfixd, macdfixdsig, macdfixdhist = MACDFIX(df['Adj Close'], signalperiod=really_fast)\n",
    "    # more momo's\n",
    "\n",
    "    mfi = MFI(df['High'], df['Low'], df['Adj Close'],df['Volume'],timeperiod=fast)\n",
    "    min_di = MINUS_DI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    min_dm = MINUS_DM(df['High'], df['Low'], timeperiod=fast)\n",
    "    momo = MOM(df['Adj Close'], timeperiod=really_fast)\n",
    "    plus_di = PLUS_DI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    plus_dm = PLUS_DM(df['High'], df['Low'], timeperiod=fast)\n",
    "    ppo = PPO(df['Adj Close'], fastperiod=really_fast, slowperiod=fast, matype=0)\n",
    "    roc = ROC(df['Adj Close'], timeperiod=fast)\n",
    "    rocp = ROCP(df['Adj Close'], timeperiod=fast)\n",
    "    rocr = ROCR(df['Adj Close'], timeperiod=fast)\n",
    "    rocr_hund = ROCR100(df['Adj Close'], timeperiod = fast)\n",
    "    rsi_fastk, rsi_fastd = STOCHRSI(df['Adj Close'], timeperiod=fast, fastk_period=slow, fastd_period=really_fast, fastd_matype=0)\n",
    "    trix = TRIX(df['Adj Close'], timeperiod=slow)\n",
    "    ult_osc = ULTOSC(df['High'], df['Low'], df['Adj Close'], timeperiod1=really_fast, timeperiod2=fast, timeperiod3=slow)\n",
    "\n",
    "\n",
    "    #old some of the first added\n",
    "    R_S_I = RSI(df['Adj Close'], timeperiod=slow)\n",
    "    slowk, slowd = STOCH(df['High'], df['Low'], df['Adj Close'], fastk_period=fast, slowk_period=slow, slowk_matype=0, slowd_period=slow, slowd_matype=0)\n",
    "    fastk, fastd = STOCHF(df['High'], df['Low'], df['Adj Close'], fastk_period=fast, fastd_period=really_fast, fastd_matype=0)\n",
    "\n",
    "    real = WILLR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "\n",
    "    # below are the TA indicators\n",
    "\n",
    "    two_crows = CDL2CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_crows = CDL3BLACKCROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_inside = CDL3INSIDE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_line = CDL3LINESTRIKE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_out = CDL3OUTSIDE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_stars = CDL3STARSINSOUTH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_soldier = CDL3WHITESOLDIERS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    baby = CDLABANDONEDBABY(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    adv = CDLADVANCEBLOCK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    belt_hold = CDLBELTHOLD(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    breakaway = CDLBREAKAWAY(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    closingmara = CDLCLOSINGMARUBOZU(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    baby_swallow = CDLCONCEALBABYSWALL(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    counter = CDLCOUNTERATTACK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    dark_cloud = CDLDARKCLOUDCOVER(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    doji = CDLDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    doji_star = CDLDOJISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    dragon_doji = CDLDRAGONFLYDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    engulf = CDLENGULFING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    evening_star = CDLEVENINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    gapside = CDLGAPSIDESIDEWHITE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    gravestone = CDLGRAVESTONEDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hammer = CDLHAMMER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hang_man = CDLHANGINGMAN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    harami = CDLHARAMI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    harami_cross = CDLHARAMICROSS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    high_wave = CDLHIGHWAVE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hikkake = CDLHIKKAKE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hikkake_mod = CDLHIKKAKEMOD(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    pidgeon = CDLHOMINGPIGEON(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    id_three_crows = CDLIDENTICAL3CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    in_neck = CDLINNECK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    inv_hammer = CDLINVERTEDHAMMER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    kicking = CDLKICKING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    kicking_len = CDLKICKINGBYLENGTH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    ladder_bot = CDLLADDERBOTTOM(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    doji_long = CDLLONGLEGGEDDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    long_line = CDLLONGLINE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    marabozu = CDLMARUBOZU(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    match_glow = CDLMATCHINGLOW(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    mat_hold = CDLMATHOLD(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    morning_doji = CDLMORNINGDOJISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    morning_star = CDLMORNINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    on_neck = CDLONNECK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    pierce = CDLPIERCING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    rickshaw = CDLRICKSHAWMAN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    rise_fall = CDLRISEFALL3METHODS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    sep_line = CDLSEPARATINGLINES(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    shooting_star = CDLSHOOTINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    sl_candle = CDLSHORTLINE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    spin_top = CDLSPINNINGTOP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    stalled = CDLSTALLEDPATTERN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    stick_sand = CDLSTICKSANDWICH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    takuri = CDLTAKURI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    tasuki_gap = CDLTASUKIGAP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    thrust = CDLTHRUSTING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    tristar = CDLTRISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_river = CDLUNIQUE3RIVER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    ud_two_gap = CDLUPSIDEGAP2CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    down_three_gap = CDLXSIDEGAP3METHODS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #76 vars\n",
    "\n",
    "    #are_all_zero = (test_TA == 0).all()\n",
    "    #true if all values are 0\n",
    "    #false if contain a non 0'''\n",
    "\n",
    "    #df.drop(['Close'], axis =1, inplace = True)\n",
    "\n",
    "    df['upper_band'] = upper_band\n",
    "    df['lower_band'] = lower_band\n",
    "    df['mid_band'] = mid_band\n",
    "    \n",
    "    df['upper_band_nine'] = upper_band_nine\n",
    "    df['lower_band_nine'] = lower_band_nine\n",
    "    df['mid_band_nine'] = mid_band_nine\n",
    "    \n",
    "    df['upper_band_one'] = upper_band_one\n",
    "    df['lower_band_one'] = lower_band_one\n",
    "    df['mid_band_one'] = mid_band_one\n",
    "    \n",
    "    df['upper_band_slow'] = upper_band_slow\n",
    "    df['lower_band_slow'] = lower_band_slow\n",
    "    df['mid_band_slow'] = mid_band_slow\n",
    "    \n",
    "    df['d_ema'] = d_ema\n",
    "    df['ht_trend'] = ht_trend\n",
    "    df['kama'] = kama\n",
    "    df['ma_fast'] = ma_fast\n",
    "    df['ma_really_fast'] = ma_really_fast\n",
    "    df['ma_slow'] = ma_slow\n",
    "    #df['mama'] = mama\n",
    "    df['mid'] = mid\n",
    "    df['mid_price'] = mid_price\n",
    "\n",
    "    df['sar'] = sar\n",
    "    df['sarext'] = sarext\n",
    "    df['sma'] = sma\n",
    "    df['tema'] = tema\n",
    "    df['trima'] = trima\n",
    "    df['wma'] = wma\n",
    "    #df['fama'] = fama\n",
    "\n",
    "    df['EMA'] = E_M_A\n",
    "    df['SlowK'] = slowk\n",
    "    df['SlowD'] = slowd\n",
    "    df['R_S_I'] = R_S_I\n",
    "    df['FastK'] = fastk\n",
    "    df['FastD'] = fastd\n",
    "    df['WilliamsR'] = real\n",
    "\n",
    "    df['atr'] = atr\n",
    "    df['natr'] = natr\n",
    "    df['t_range'] = t_range\n",
    "\n",
    "\n",
    "    #df['na_tr'] = natr\n",
    "\n",
    "    df['OBV'] = O_B_V\n",
    "    df['ADOSC'] = A_D_O_S_C\n",
    "    df['ogchaikin'] = O_G_chaikin\n",
    "    df['HTDCperiod'] = HT_DCper\n",
    "    df['HTDCphase'] = HT_DCphase\n",
    "    df['inphase'] = inphase\n",
    "    df['quad'] = quad\n",
    "    df['rsin'] = r_sin\n",
    "    df['leadsin'] = leadsin\n",
    "\n",
    "    df['mfi'] = mfi\n",
    "    df['min_di'] = min_di\n",
    "    df['min_dm'] = min_dm\n",
    "    df['momo'] = momo\n",
    "    df['plus_di'] = plus_di\n",
    "    df['plus_dm'] = plus_dm\n",
    "    df['ppo'] = ppo\n",
    "    df['roc'] = roc\n",
    "    df['rocp'] = rocp\n",
    "\n",
    "    df['rocr'] = rocr\n",
    "    df['rocr_hund'] = rocr_hund\n",
    "    df['rsi_fastk'] = rsi_fastk\n",
    "    df['rsi_fastd'] = rsi_fastd\n",
    "    df['trix'] = trix\n",
    "    df['ult_osc'] = ult_osc\n",
    "\n",
    "    df['adx'] = adx\n",
    "    df['adxr'] = adxr\n",
    "    df['apo'] = apo\n",
    "    df['aroon_d'] = aroon_d\n",
    "    df['aroon_u'] = aroon_u\n",
    "    df['aroon_osc'] = aroon_osc\n",
    "    df['bop'] = bop\n",
    "    df['cci'] = cci\n",
    "    df['cmo'] = cmo\n",
    "\n",
    "    df['dx'] = dx\n",
    "    df['macd'] = macd\n",
    "    df['macdsig'] = macdsig\n",
    "    df['macdhist'] = macdhist\n",
    "    df['macdex'] = macdex\n",
    "    df['macdexsig'] = macdexsig\n",
    "    df['macdexhist'] = macdexhist\n",
    "    df['macdfixd'] = macdfixd\n",
    "    df['macdfixdsig'] = macdfixdsig\n",
    "    df['macdfixdhist'] = macdfixdhist\n",
    "\n",
    "    df['two_crows'] = two_crows\n",
    "    df['three_crows'] = three_crows\n",
    "    df['three_inside'] = three_inside\n",
    "    df['three_line'] = three_line\n",
    "    df['three_out'] = three_out\n",
    "    df['three_stars'] = three_stars\n",
    "    df['three_soldier'] = three_soldier\n",
    "    df['baby'] = baby\n",
    "    df['adv'] = adv\n",
    "    df['belt_hold'] = belt_hold\n",
    "    df['breakaway'] = breakaway\n",
    "    df['closingmara'] = closingmara\n",
    "    df['baby_swallow'] = belt_hold\n",
    "\n",
    "    df['counter'] = counter\n",
    "    df['dark_cloud'] = dark_cloud\n",
    "    df['doji'] = doji\n",
    "    df['doji_star'] = doji_star\n",
    "    df['dragon_doji'] = dragon_doji\n",
    "    df['engulf'] = engulf\n",
    "    df['evening_star'] = evening_star\n",
    "    df['gapside'] = gapside\n",
    "    df['gravestone'] = gravestone\n",
    "    df['hammer'] = hammer\n",
    "    df['hang_man'] = hang_man\n",
    "    df['harami'] = harami\n",
    "    df['harami_cross'] = harami_cross\n",
    "\n",
    "    df['high_wave'] = high_wave\n",
    "    df['hikkake'] = hikkake\n",
    "    df['hikkake_mod'] = hikkake_mod\n",
    "    df['pidgeon'] = pidgeon\n",
    "    df['id_three_crows'] = id_three_crows\n",
    "    df['in_neck'] = in_neck\n",
    "    df['inv_hammer'] = inv_hammer\n",
    "    df['kicking'] = kicking\n",
    "    df['kicking_len'] = kicking_len\n",
    "    df['ladder_bot'] = ladder_bot\n",
    "    df['doji_long'] = doji_long\n",
    "    df['long_line'] = long_line\n",
    "    df['marabozu'] = marabozu\n",
    "                                                    # this is  a comment\n",
    "    df['match_glow'] = match_glow\n",
    "    df['mat_hold'] = mat_hold\n",
    "    df['morning_doji'] = morning_doji\n",
    "    df['morning_star'] = morning_star\n",
    "    df['on_neck'] = on_neck\n",
    "    df['pierce'] = pierce\n",
    "    df['rickshaw'] = rickshaw\n",
    "    df['rise_fall'] = rise_fall\n",
    "    df['sep_line'] = sep_line\n",
    "    df['shooting_star'] = shooting_star\n",
    "    df['sl_candle'] = sl_candle\n",
    "    df['spin_top'] = spin_top\n",
    "    df['stalled'] = stalled\n",
    "\n",
    "    df['stick_sand'] = stick_sand\n",
    "    df['takuri'] = takuri\n",
    "    df['tasuki_gap'] = tasuki_gap\n",
    "    df['thrust'] = thrust\n",
    "    df['tristar'] = tristar\n",
    "    df['three_river'] = three_river\n",
    "    df['ud_two_gap'] = ud_two_gap\n",
    "    df['down_three_gap'] = down_three_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suspected-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag(num_lag_cols, this_df):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    lag_cols = ['ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc','adj_close',\n",
    "                'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line',\n",
    "                'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji',\n",
    "                'engulf','evening_star','gapside','gravestone','hammer',\n",
    "                'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows',\n",
    "                'in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck',\n",
    "                'pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river',\n",
    "                'ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                'mid_band','d_ema','ht_trend','kama','ma_fast','ma_really_fast','ma_slow','mid','mid_price','sar',\n",
    "                'sarext','sma','tema','trima','wma',\n",
    "                'adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd',\n",
    "                'macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix',\n",
    "                'ult_osc', 'atr','natr','t_range',\n",
    "                'upper_band_nine','lower_band_nine','mid_band_nine','upper_band_one','lower_band_one','mid_band_one',\n",
    "                'upper_band_slow','lower_band_slow','mid_band_slow'\n",
    "                ]\n",
    "\n",
    "    shift_range = [x+1 for x in range(num_lag_cols)]\n",
    "\n",
    "    for shift in shift_range:\n",
    "        train_shift = this_df[merging_keys + lag_cols].copy()\n",
    "\n",
    "        # E.g. order_day of 0 becomes 1, for shift = 1.\n",
    "        # So when this is merged with order_day of 1 in df, this will represent lag of 1.\n",
    "        train_shift['order_day'] = train_shift['order_day'] + shift\n",
    "\n",
    "        foo = lambda x: '{}_lag_{}'.format(x, shift) if x in lag_cols else x\n",
    "        train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "        this_df = pd.merge(this_df, train_shift, on=merging_keys, how='left') #.fillna(0)\n",
    "\n",
    "    del train_shift\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "\n",
    "    print(f\"completed lagging in {tic_toc:0.4f} min\")\n",
    "    \n",
    "\n",
    "    return this_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impossible-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, window_size):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    print(window_size)\n",
    "    \n",
    "    df.loc[df['adj_close'] >= df['adj_close'].rolling(window_size, center = True).quantile(.9, interpolation='linear'), 'labels'] = 0 # sell\n",
    "    \n",
    "    df.loc[df['adj_close'] <= df['adj_close'].rolling(window_size, center = True).quantile(.1, interpolation='linear'), 'labels'] = 1 #buy\n",
    "    \n",
    "    df['labels'].fillna(2, inplace = True)\n",
    "    \n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "    \n",
    "    #BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "    print(f\"completed labels in {tic_toc:0.4f} min\")\n",
    "    \n",
    "    #return list_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "practical-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scale(num_interval_lag):\n",
    "\n",
    "    cols_to_scale = ['adj_close','ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl',\n",
    "                     'range_oc', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                    'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line',\n",
    "                     'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                    'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star',\n",
    "                     'dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                    'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows',\n",
    "                     'in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                    'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star',\n",
    "                     'on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                    'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar',\n",
    "                     'three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                    'mid_band','d_ema','ht_trend','kama','ma_fast','ma_really_fast','ma_slow','mid','mid_price',\n",
    "                     'sar','sarext','sma','tema',\n",
    "                     'trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                    'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist',\n",
    "                     'macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                    'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd',\n",
    "                     'trix','ult_osc', 'atr','natr','t_range',\n",
    "                    'upper_band_nine','lower_band_nine','mid_band_nine','upper_band_one','lower_band_one',\n",
    "                     'mid_band_one','upper_band_slow','lower_band_slow','mid_band_slow' \n",
    "                    ]\n",
    "\n",
    "    for i in range(1,num_interval_lag+1):\n",
    "        cols_to_scale.append(\"ema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"r_s_i_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"fastk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"fastd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"williamsr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"volume_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"range_hl_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"range_oc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adj_close_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"upper_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"lower_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_band_lag_\"+str(i))\n",
    "        \n",
    "        cols_to_scale.append(\"upper_band_nine_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"lower_band_nine_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_band_nine_lag_\"+str(i))\n",
    "        \n",
    "        cols_to_scale.append(\"upper_band_one_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"lower_band_one_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_band_one_lag_\"+str(i))\n",
    "        \n",
    "        cols_to_scale.append(\"upper_band_slow_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"lower_band_slow_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_band_slow_lag_\"+str(i))\n",
    "        \n",
    "        cols_to_scale.append(\"d_ema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ht_trend_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kama_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ma_fast_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ma_really_fast_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ma_slow_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_price_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sar_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sarext_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sma_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"trima_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"wma_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"atr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"natr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"t_range_lag_\"+str(i))\n",
    "\n",
    "        #momentum indicator lag cols\n",
    "\n",
    "        cols_to_scale.append(\"adx_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adxr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"apo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_d_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_u_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_osc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"bop_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"cci_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"cmo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"dx_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdhist_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdex_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"mfi_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"min_di_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"min_dm_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"momo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"plus_di_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"plus_dm_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ppo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"roc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocp_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocr_hund_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsi_fastk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsi_fastd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"trix_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ult_osc_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"macdexsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdexhist_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixdsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixdhist_lag_\"+str(i))\n",
    "\n",
    "\n",
    "        #cols_to_scale.append(\"mama_lag_\"+str(i))\n",
    "        #cols_to_scale.append(\"NATR_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"obv_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"adosc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ogchaikin_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"htdcperiod_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"htdcphase_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"inphase_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"quad_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsin_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"leadsin_lag_\"+str(i))\n",
    "        #cols_to_scale.append(\"fama_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"two_crows_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"three_crows_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_inside_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_out_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_stars_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_soldier_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"baby_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adv_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"belt_hold_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"breakaway_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"closingmara_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"baby_swallow_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"counter_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"dark_cloud_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"dragon_doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"engulf_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"evening_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"gapside_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"gravestone_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hammer_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hang_man_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"harami_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"harami_cross_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"high_wave_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"hikkake_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hikkake_mod_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"pidgeon_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"id_three_crows_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"in_neck_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"inv_hammer_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kicking_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kicking_len_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ladder_bot_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_long_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"long_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"marabozu_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"match_glow_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"mat_hold_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"morning_doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"morning_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"on_neck_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"pierce_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rickshaw_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rise_fall_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sep_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"shooting_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sl_candle_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"spin_top_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"stalled_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"stick_sand_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"takuri_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tasuki_gap_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"thrust_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tristar_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_river_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ud_two_gap_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"down_three_gap_lag_\"+str(i))\n",
    "\n",
    "    return cols_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'NVAX'\n",
    "df = pd.read_csv(r'C:\\Users\\Michael\\Desktop\\Python\\Stonks\\Data_Scrape\\file_storage\\US1.CAT_200319_210319.txt'\n",
    "                 , parse_dates = [['<DATE>', '<TIME>']])\n",
    "df.columns = ['datetime','Open','High','Low','Adj Close','Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['datetime'])\n",
    "adj_close_list = df['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fracdiff import FracdiffStat\n",
    "from fracdiff import Fracdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "AV = AutoViz_Class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-plaza",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac_diff = df.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac_diff = test_frac_diff.values.reshape(-1,test_frac_diff.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_frac_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FracdiffStat(window = 60)\n",
    "frac_diff_out = f.fit_transform(test_frac_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = Fracdiff(d = d_val, window = 60)\n",
    "#frac_diff_out = f.transform(test_frac_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frac = pd.DataFrame(frac_diff_out, index = df.index, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frac.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#2 min ticker\n",
    "# 30 intervals = 1 hour << OLD\n",
    "# 195 intervals = trading day'''\n",
    "                                            # there are more intervals that we can use / change\n",
    "    \n",
    "# 390 intervals / day < 1 min intervals\n",
    "# 390 < 1 day, 780 < 2 day, 1170 < 3 days, 1560 < 4 day, 1950 < 5 days\n",
    "# 2340 < 6 days, 2730 < 7 days, 3120 < 8 days, 3510 < 9 days,\n",
    "# 3900 < 10 days, 4290 < 11 days, 4680 < 12 days, 5070 < 13 days,\n",
    "# 5460 < 14 days, 5850 < 15 days, 6240 < 16 days, 6630 < 17 days,\n",
    "\n",
    "#min tickers\n",
    "#\n",
    "really_fast = 30\n",
    "fast = 60\n",
    "slow = 180\n",
    "\n",
    "add_indicators()\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n",
    "\n",
    "# Change all column headings to be lower case, and remove spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frac.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['open', 'high', 'low','adj_close']] = df_frac[['Open', 'High', 'Low', 'Adj Close']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get difference between high and low of each day\n",
    "df['range_hl'] = df['high'] - df['low']\n",
    "df.drop(['high', 'low'], axis=1, inplace=True)\n",
    "# Get difference between open and close of each day\n",
    "df['range_oc'] = df['open'] - df['adj_close']\n",
    "df.drop(['open'], axis=1, inplace=True)\n",
    "# Add a column 'order_day' to indicate the order of the rows by date\n",
    "df['order_day'] = [x for x in list(range(len(df)))]\n",
    "# merging_keys\n",
    "merging_keys = ['order_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interval_lag = 60\n",
    "\n",
    "df = add_lag(num_interval_lag, df)\n",
    "\n",
    "#df['adj_close'] = df['adj_close'].shift(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#df.tail(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-stadium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "#types_list = df.dtypes\n",
    "#types_list.to_dict()\n",
    "\n",
    "df = df.select_dtypes(include = ['float64']).astype('float32', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = df_frac.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_labels(df)\n",
    "\n",
    "\n",
    "# 390 intervals / day < 1 min intervals\n",
    "# 390 < 1 day, 780 < 2 day, 1170 < 3 days, 1560 < 4 day, 1950 < 5 days\n",
    "# 2340 < 6 days, 2730 < 7 days, 3120 < 8 days, 3510 < 9 days,\n",
    "# 3900 < 10 days, 4290 < 11 days, 4680 < 12 days, 5070 < 13 days,\n",
    "# 5460 < 14 days, 5850 < 15 days, 6240 < 16 days, 6630 < 17 days,\n",
    "\n",
    "window_size = 60\n",
    "add_labels(df, window_size)\n",
    "\n",
    "\n",
    "#print(df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_true_markers = df.index[df['labels']==1].tolist()\n",
    "sell_true_markers = df.index[df['labels']==0].tolist()\n",
    "#BUY => 1, SELL => 0, HOLD => 2\n",
    "all_markers = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-brazil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.plot(df['datetime'], adj_close_list)\n",
    "plt.plot(df['datetime'], adj_close_list, 'g^', markevery = buy_true_markers)\n",
    "plt.plot(df['datetime'], adj_close_list, 'rv', markevery = sell_true_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-indonesian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(df['datetime'], adj_close_list)\n",
    "plt.plot(df['datetime'], df['upper_band_nine'], 'r:')\n",
    "plt.plot(df['datetime'], df['lower_band_nine'], 'g:')\n",
    "plt.plot(df['datetime'], adj_close_list, 'g^', markevery = buy_true_markers)\n",
    "plt.plot(df['datetime'], adj_close_list, 'rv', markevery = sell_true_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vals = df['labels'].value_counts()\n",
    "df['labels'].value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_buys = label_vals[1]\n",
    "num_sells = label_vals[0]\n",
    "num_holds = label_vals[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "least_vals = min(num_buys, num_sells, num_holds)\n",
    "#print(least_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_factor = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_buys = imp_factor * (least_vals / num_buys)\n",
    "weight_sells = imp_factor * (least_vals / num_sells)\n",
    "weight_holds = least_vals / num_holds\n",
    "print(weight_buys)\n",
    "print(weight_sells)\n",
    "print(weight_holds)\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list = df.index[df['labels'] == 1].tolist()\n",
    "sell_list = df.index[df['labels'] == 0].tolist()\n",
    "hold_list = df.index[df['labels'] == 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[buy_list, 'weights'] = weight_buys\n",
    "df.loc[sell_list, 'weights'] = weight_sells\n",
    "df.loc[hold_list, 'weights'] = weight_holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-profile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['weights'].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-influence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rem = ['weights','adj_close','ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line', 'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows','in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                'mid_band','d_ema','ht_trend','kama','ma_fast','ma_really_fast','ma_slow','mid','mid_price','sar','sarext','sma','tema','trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix','ult_osc', 'atr','natr','t_range',\n",
    "                'upper_band_nine','lower_band_nine','mid_band_nine','upper_band_one','lower_band_one','mid_band_one','upper_band_slow','lower_band_slow','mid_band_slow' \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_vals_list = df['adj_close']\n",
    "dates_list = df['datetime']\n",
    "weights_list = df['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols_to_rem, axis = 1, inplace = True, errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "num_test = int(.2*len(df))\n",
    "num_train = len(df) - num_test\n",
    "\n",
    "\n",
    "print(df['labels'].iloc[[-1]])\n",
    "\n",
    "#train_close_vals = close_vals_list[:num_train]\n",
    "#test_close_vals = close_vals_list[num_train:]\n",
    "\n",
    "#test_dates_list = test['date']\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = add_scale(num_interval_lag)\n",
    "\n",
    "#cols_to_scale.remove(cols_to_rem)\n",
    "\n",
    "# Do scaling for train set\n",
    "# Here we only scale the train dataset, and not the entire dataset to prevent information leak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in cols_to_rem:\n",
    "\n",
    "    if element in cols_to_scale:\n",
    "\n",
    "        cols_to_scale.remove(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[slow:]\n",
    "weights_list = weights_list[slow:]\n",
    "\n",
    "close_vals_list = close_vals_list[slow:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = df[cols_to_scale]\n",
    "all_y = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size=0.2, shuffle = False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle = False) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "#scaling test dataset\n",
    "\n",
    "#X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(all_X_scaled, all_y, test_size=0.2, shuffle = False)\n",
    "\n",
    "#X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.25, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_len = len(y_test)\n",
    "print(test_set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates_list = dates_list[-test_set_len:]\n",
    "\n",
    "test_vals_list = close_vals_list[-test_set_len:]\n",
    "\n",
    "test_labels = all_markers[-test_set_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buy_true_test_markers = test_labels.values == 1\n",
    "sell_true_test_markers = test_labels.values == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-graham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.plot(test_dates_list, test_vals_list)\n",
    "plt.plot(test_dates_list, test_vals_list, 'g^', markevery=buy_true_test_markers)\n",
    "plt.plot(test_dates_list, test_vals_list, 'rv', markevery=sell_true_test_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(X_train)\n",
    "val_len = len(X_val)\n",
    "test_len = len(X_test)\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights = weights_list[:train_len]\n",
    "val_weights = weights_list[train_len:train_len + val_len]\n",
    "test_weights = weights_list[train_len + val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train, label = y_train, weight = train_weights)\n",
    "d_val = xgb.DMatrix(X_val, label = y_val, weight = val_weights)\n",
    "d_test = xgb.DMatrix(X_test, label = y_test, weight = test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_frame = pd.DataFrame(val_weights)\n",
    "#BUY => 1, SELL => 0, HOLD => 2\n",
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from typing import Tuple\n",
    "\n",
    "def recall(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "    ''' Root mean squared log error metric.'''\n",
    "    y = dtrain.get_label()\n",
    "    \n",
    "    inter_vals = pd.DataFrame(y)\n",
    "    vals_all = inter_vals.value_counts()\n",
    "    \n",
    "    #BUY => 1, SELL => 0, HOLD => 2\n",
    "    \n",
    "    #print(predt)\n",
    "    \n",
    "    inter_num_buys = vals_all[1]\n",
    "    inter_num_sells = vals_all[0]\n",
    "    inter_num_holds = vals_all[2]\n",
    "    \n",
    "    least_vals = min(inter_num_buys, inter_num_sells, inter_num_holds)\n",
    "    \n",
    "    imp_factor = 5\n",
    "    \n",
    "    inter_weight_buys = imp_factor * (least_vals / inter_num_buys)\n",
    "    inter_weight_sells = imp_factor * (least_vals / inter_num_sells)\n",
    "    inter_weight_holds = least_vals / inter_num_holds\n",
    "    \n",
    "    \n",
    "    #print(inter_weight_buys)\n",
    "    #print(inter_weight_sells)\n",
    "    #print(inter_weight_holds)\n",
    "    \n",
    "    #predt[predt < -1] = -1 + 1e-6\n",
    "\n",
    "    #print(len(predt))\n",
    "    #print(predt.shape)\n",
    "    \n",
    "    y_pred = [None] * len(predt)\n",
    "    inter_weights = [None] * len(predt)\n",
    "    for x in range(len(predt)):\n",
    "        \n",
    "        val_0 = predt[x,0]\n",
    "        val_1 = predt[x,1]\n",
    "        val_2 = predt[x,2]\n",
    "        \n",
    "        pos = max(val_0, val_1, val_2)\n",
    "        \n",
    "        if pos == val_0:\n",
    "            y_pred[x] = 0\n",
    "            inter_weights[x] = inter_weight_sells\n",
    "        elif pos == val_1:\n",
    "            y_pred[x] = 1\n",
    "            inter_weights[x] = inter_weight_buys\n",
    "        elif pos == val_2:\n",
    "            y_pred[x] = 2\n",
    "            inter_weights[x] = inter_weight_holds\n",
    "            \n",
    "    #breakpoint\n",
    "    #print(y_pred)\n",
    "    #BUY => 1, SELL => 0, HOLD => 2\n",
    "    \n",
    "    rec_return_sell = recall_score(y, y_pred, labels = [0], average = 'weighted', sample_weight = inter_weights)\n",
    "    rec_return_buy = recall_score(y, y_pred, labels = [1], average = 'weighted', sample_weight = inter_weights)\n",
    "\n",
    "    \n",
    "    #rec_return = (rec_return_sell + rec_return_buy) / 2\n",
    "    #prec_return = (prec_return_sell + prec_return_buy) / 2\n",
    "    \n",
    "    #print(rec_return_sell)\n",
    "    #print(rec_return_buy)\n",
    "    \n",
    "    rec_mult = rec_return_sell * rec_return_buy\n",
    "    \n",
    "    return [('adj_recall', float(rec_mult))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(d_train, 'train'), (d_val, 'val')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train.MetaInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "params = {'tree_method': 'gpu_hist',\n",
    "            'gpu_id': 0,\n",
    "            'disable_default_eval_metric':True,\n",
    "            'max_depth':15,\n",
    "            'learning_rate':0.75,\n",
    "            #'eval_metric': ['merror','mlogloss'],\n",
    "            'objective': 'multi:softprob',\n",
    "            'min_child_weight':1,\n",
    "            'subsample':1,\n",
    "            'num_class': 3,\n",
    "            'gamma':0.5,\n",
    "            'verbosity': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del frac_diff_out\n",
    "#del Fracdiff, add_indicators, add_lag, add_scale, add_labels\n",
    "#del all_X\n",
    "#del X_test, X_train, X_val\n",
    "#del add_labels\n",
    "#del df_frac\n",
    "#del f\n",
    "#del get_functions, get_function_groups\n",
    "#del talib\n",
    "#del train_test_split\n",
    "#del y_test, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-bathroom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#num_round = 1000\n",
    "bst = xgb.train(params,\n",
    "                d_train,\n",
    "                num_boost_round = 1000,\n",
    "                feval = recall,\n",
    "                evals = eval_set,\n",
    "                maximize = True,\n",
    "                evals_result = evals_result,\n",
    "                early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(evals_result['val']['adj_recall'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, evals_result['train']['adj_recall'], label='Train')\n",
    "ax.plot(x_axis, evals_result['val']['adj_recall'], label='Val')\n",
    "ax.legend()\n",
    "plt.ylabel('adj_recall')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.title('XGBoost adj_recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = bst.best_ntree_limit\n",
    "print(how_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.best_iteration\n",
    "\n",
    "#how_many = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-royal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(params,\n",
    "                d_train,\n",
    "                num_boost_round = how_many,\n",
    "                feval = recall,\n",
    "                maximize = True,\n",
    "                evals = eval_set,\n",
    "                evals_result = evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)\n",
    "\n",
    "preds_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-forward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds = np.asarray([np.argmax(line) for line in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(best_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-colors",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(evals_result['val']['adj_recall'])\n",
    "x_axis = range(0, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, evals_result['train']['adj_recall'], label='Train')\n",
    "ax.plot(x_axis, evals_result['val']['adj_recall'], label='Val')\n",
    "ax.legend()\n",
    "plt.ylabel('adj_recall')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.title('XGBoost adj_recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-couple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "xgb.plot_importance(bst, max_num_features = 50)\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "xgb.plot_tree(bst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = bst.get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keys = sorted(feature_dict, key=feature_dict.get, reverse=True)[:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keys.append('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_df = df[my_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_df.to_csv(r'C:\\Users\\Michael\\Desktop\\Python\\Stonks\\Data_Scrape\\file_storage\\analyze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-copying",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "dft = AV.AutoViz(r'C:\\Users\\Michael\\Desktop\\Python\\Stonks\\Data_Scrape\\file_storage\\analyze.csv',\n",
    "                 sep=',', depVar='labels', dfte=analyze_df, header=0, verbose=2,\n",
    "                            lowess=False,chart_format='png',max_rows_analyzed=30000,max_cols_analyzed=30)\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-steps",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "target_names = ['Sell', 'Buy', 'Hold']\n",
    "print(classification_report_imbalanced(y_test.values, pred_df.values, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test.values.tolist(), pred_df.values.tolist())\n",
    "conf_mat_norm = confusion_matrix(y_test.values.tolist(), pred_df.values.tolist(), normalize = 'true')\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(conf_mat_norm, display_labels = target_names)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_df.values[-1])\n",
    "#last class label\n",
    "#plt.ylabel('BUY => 1, SELL => 0, HOLD => 2')\n",
    "test_dates_list[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list_markers = pred_df.index[pred_df[0]==1].tolist()\n",
    "sell_list_markers = pred_df.index[pred_df[0]==0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-packet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "plt.plot(test_dates_list, test_vals_list)\n",
    "plt.plot(test_dates_list, test_vals_list, 'g^', markevery=buy_list_markers)\n",
    "plt.plot(test_dates_list, test_vals_list, 'rv', markevery=sell_list_markers)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "plt.plot(test_dates_list, test_vals_list)\n",
    "plt.plot(test_dates_list, test_vals_list, 'g^', markevery=buy_true_test_markers)\n",
    "plt.plot(test_dates_list, test_vals_list, 'rv', markevery=sell_true_test_markers)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['adj_close'] = close_vals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['adj_close'] = df_reg['adj_close'].shift(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.tail(-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.drop(['labels'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['adj_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X_reg = df_reg[cols_to_scale]\n",
    "all_y_reg = df_reg['adj_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-panama",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(all_X_reg, all_y_reg, \n",
    "                                                                    test_size=0.2, shuffle = False)\n",
    "\n",
    "X_train_reg, X_val_reg, y_train_reg, y_val_reg = train_test_split(X_train_reg, y_train_reg,\n",
    "                                                                  test_size=0.25, shuffle = False) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_reg = xgb.DMatrix(X_train_reg, label = y_train_reg)\n",
    "d_val_reg = xgb.DMatrix(X_val_reg, label = y_val_reg)\n",
    "d_test_reg = xgb.DMatrix(X_test_reg, label = y_test_reg)\n",
    "\n",
    "eval_set_reg = [(d_train_reg, 'train'), (d_val_reg, 'val')]\n",
    "\n",
    "evals_result_reg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'tree_method': 'gpu_hist',\n",
    "            'gpu_id': 0,\n",
    "            'n_estimators': 500,\n",
    "            'max_depth':25,\n",
    "            'learning_rate':0.1,\n",
    "            'eval_metric': 'mae',\n",
    "            'objective': 'reg:gamma',\n",
    "            'min_child_weight':0.25,\n",
    "            'subsample':1,\n",
    "            'gamma':0.05,\n",
    "            'verbosity': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-coral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(params,\n",
    "                d_train_reg,\n",
    "                num_boost_round = 1000,\n",
    "                evals = eval_set_reg,\n",
    "                evals_result = evals_result_reg,\n",
    "                early_stopping_rounds = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(evals_result_reg['val']['mae'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, evals_result_reg['train']['mae'], label='Train')\n",
    "ax.plot(x_axis, evals_result_reg['val']['mae'], label='Val')\n",
    "\n",
    "ax.legend()\n",
    "plt.ylabel('errors')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.title('XGBoost errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict(d_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "plt.plot(test_dates_list[6:], y_test_reg)\n",
    "\n",
    "\n",
    "plt.plot(test_dates_list[6:], preds)\n",
    "\n",
    "plt.legend(['true','pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-leadership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-metabolism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
