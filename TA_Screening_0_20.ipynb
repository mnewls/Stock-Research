{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from yahoo_fin import stock_info as si\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import talib\n",
    "from talib import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators():\n",
    "        \n",
    "    upper_band, mid_band, lower_band = BBANDS(df['Adj Close'],timeperiod=really_fast, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    d_ema = DEMA(df['Adj Close'], timeperiod=really_fast)\n",
    "    E_M_A = EMA(df['Adj Close'], timeperiod=fast)\n",
    "    ht_trend = HT_TRENDLINE(df['Adj Close'])\n",
    "    kama = KAMA(df['Adj Close'], timeperiod=fast)\n",
    "    ma = MA(df['Adj Close'], timeperiod=fast, matype=0)\n",
    "    #mama, fama = MAMA(df['Adj Close'], fastlimit=really_fast, slowlimit=slow) < this gave me issues?\n",
    "    #mavp = MAVP(df['Adj Close'])\n",
    "    mid = MIDPOINT(df['Adj Close'], timeperiod=fast)\n",
    "    mid_price = MIDPRICE(df['High'], df['Low'], timeperiod=fast)\n",
    "    sar = SAR(df['High'], df['Low'], acceleration=.02, maximum=.2)\n",
    "    sarext = SAREXT(df['High'], df['Low'], startvalue=0, offsetonreverse=0, accelerationinitlong=.02, accelerationlong=.02, accelerationmaxlong=.2, accelerationinitshort=.02, accelerationshort=.02, accelerationmaxshort=.2)\n",
    "    sma = SMA(df['Adj Close'], timeperiod=slow)\n",
    "    tema = TEMA(df['Adj Close'], timeperiod=slow)\n",
    "    trima = TRIMA(df['Adj Close'], timeperiod=slow)\n",
    "    wma = WMA(df['Adj Close'], timeperiod=slow)\n",
    "\n",
    "    #this is some of the beginning stuff\n",
    "\n",
    "    O_B_V = OBV(df['Adj Close'], df['Volume'])\n",
    "    A_D_O_S_C = ADOSC(df['High'], df['Low'], df['Adj Close'], df['Volume'], fastperiod=fast, slowperiod=slow)\n",
    "    O_G_chaikin = AD(df['High'], df['Low'], df['Adj Close'], df['Volume'])\n",
    "    HT_DCper = HT_DCPERIOD(df['Adj Close'])\n",
    "    HT_DCphase = HT_DCPHASE(df['Adj Close'])\n",
    "    inphase, quad = HT_PHASOR(df['Adj Close'])\n",
    "    r_sin, leadsin = HT_SINE(df['Adj Close'])\n",
    "\n",
    "    #volatility\n",
    "    atr = ATR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "    natr = NATR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "    t_range = TRANGE(df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #below here are momentum ind\n",
    "\n",
    "    adx = ADX(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    adxr = ADXR(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    apo = APO(df['Adj Close'], fastperiod=really_fast, slowperiod=fast, matype=0)\n",
    "    aroon_d, aroon_u = AROON(df['High'], df['Low'], timeperiod=fast)\n",
    "    aroon_osc = AROONOSC(df['High'], df['Low'], timeperiod=fast)\n",
    "    bop = BOP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    cci = CCI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    cmo = CMO(df['Adj Close'], timeperiod=fast)\n",
    "    dx = DX(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    macd, macdsig, macdhist = MACD(df['Adj Close'], fastperiod=fast, slowperiod=slow, signalperiod=really_fast)\n",
    "    macdex, macdexsig, macdexhist = MACDEXT(df['Adj Close'], fastperiod=fast, fastmatype=0, slowperiod=slow, slowmatype=0, signalperiod=really_fast, signalmatype=0)\n",
    "    macdfixd, macdfixdsig, macdfixdhist = MACDFIX(df['Adj Close'], signalperiod=really_fast)\n",
    "    # more momo's\n",
    "\n",
    "    mfi = MFI(df['High'], df['Low'], df['Adj Close'],df['Volume'],timeperiod=fast)\n",
    "    min_di = MINUS_DI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    min_dm = MINUS_DM(df['High'], df['Low'], timeperiod=fast)\n",
    "    momo = MOM(df['Adj Close'], timeperiod=really_fast)\n",
    "    plus_di = PLUS_DI(df['High'], df['Low'], df['Adj Close'], timeperiod=fast)\n",
    "    plus_dm = PLUS_DM(df['High'], df['Low'], timeperiod=fast)\n",
    "    ppo = PPO(df['Adj Close'], fastperiod=really_fast, slowperiod=fast, matype=0)\n",
    "    roc = ROC(df['Adj Close'], timeperiod=fast)\n",
    "    rocp = ROCP(df['Adj Close'], timeperiod=fast)\n",
    "    rocr = ROCR(df['Adj Close'], timeperiod=fast)\n",
    "    rocr_hund = ROCR100(df['Adj Close'], timeperiod = fast)\n",
    "    rsi_fastk, rsi_fastd = STOCHRSI(df['Adj Close'], timeperiod=fast, fastk_period=slow, fastd_period=really_fast, fastd_matype=0)\n",
    "    trix = TRIX(df['Adj Close'], timeperiod=slow)\n",
    "    ult_osc = ULTOSC(df['High'], df['Low'], df['Adj Close'], timeperiod1=really_fast, timeperiod2=fast, timeperiod3=slow)\n",
    "\n",
    "\n",
    "    #old some of the first added\n",
    "    R_S_I = RSI(df['Adj Close'], timeperiod=slow)\n",
    "    slowk, slowd = STOCH(df['High'], df['Low'], df['Adj Close'], fastk_period=fast, slowk_period=slow, slowk_matype=0, slowd_period=slow, slowd_matype=0)\n",
    "    fastk, fastd = STOCHF(df['High'], df['Low'], df['Adj Close'], fastk_period=fast, fastd_period=really_fast, fastd_matype=0)\n",
    "\n",
    "    real = WILLR(df['High'], df['Low'], df['Adj Close'], timeperiod=slow)\n",
    "\n",
    "    # below are the TA indicators\n",
    "\n",
    "    two_crows = CDL2CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_crows = CDL3BLACKCROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_inside = CDL3INSIDE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_line = CDL3LINESTRIKE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_out = CDL3OUTSIDE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_stars = CDL3STARSINSOUTH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_soldier = CDL3WHITESOLDIERS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    baby = CDLABANDONEDBABY(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    adv = CDLADVANCEBLOCK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    belt_hold = CDLBELTHOLD(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    breakaway = CDLBREAKAWAY(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    closingmara = CDLCLOSINGMARUBOZU(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    baby_swallow = CDLCONCEALBABYSWALL(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    counter = CDLCOUNTERATTACK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    dark_cloud = CDLDARKCLOUDCOVER(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    doji = CDLDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    doji_star = CDLDOJISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    dragon_doji = CDLDRAGONFLYDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    engulf = CDLENGULFING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    evening_star = CDLEVENINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    gapside = CDLGAPSIDESIDEWHITE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    gravestone = CDLGRAVESTONEDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hammer = CDLHAMMER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hang_man = CDLHANGINGMAN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    harami = CDLHARAMI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    harami_cross = CDLHARAMICROSS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    high_wave = CDLHIGHWAVE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hikkake = CDLHIKKAKE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    hikkake_mod = CDLHIKKAKEMOD(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    pidgeon = CDLHOMINGPIGEON(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    id_three_crows = CDLIDENTICAL3CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    in_neck = CDLINNECK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    inv_hammer = CDLINVERTEDHAMMER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    kicking = CDLKICKING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    kicking_len = CDLKICKINGBYLENGTH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    ladder_bot = CDLLADDERBOTTOM(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    doji_long = CDLLONGLEGGEDDOJI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    long_line = CDLLONGLINE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    marabozu = CDLMARUBOZU(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    match_glow = CDLMATCHINGLOW(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    mat_hold = CDLMATHOLD(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    morning_doji = CDLMORNINGDOJISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    morning_star = CDLMORNINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'], penetration=0)\n",
    "    on_neck = CDLONNECK(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    pierce = CDLPIERCING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    rickshaw = CDLRICKSHAWMAN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    rise_fall = CDLRISEFALL3METHODS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    sep_line = CDLSEPARATINGLINES(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    shooting_star = CDLSHOOTINGSTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    sl_candle = CDLSHORTLINE(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    spin_top = CDLSPINNINGTOP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    stalled = CDLSTALLEDPATTERN(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #more TA\n",
    "\n",
    "    stick_sand = CDLSTICKSANDWICH(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    takuri = CDLTAKURI(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    tasuki_gap = CDLTASUKIGAP(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    thrust = CDLTHRUSTING(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    tristar = CDLTRISTAR(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    three_river = CDLUNIQUE3RIVER(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    ud_two_gap = CDLUPSIDEGAP2CROWS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "    down_three_gap = CDLXSIDEGAP3METHODS(df['Open'], df['High'], df['Low'], df['Adj Close'])\n",
    "\n",
    "    #76 vars\n",
    "\n",
    "    #are_all_zero = (test_TA == 0).all()\n",
    "    #true if all values are 0\n",
    "    #false if contain a non 0'''\n",
    "\n",
    "    df.drop(['Close'], axis =1, inplace = True)\n",
    "\n",
    "    df['upper_band'] = upper_band\n",
    "    df['lower_band'] = lower_band\n",
    "    df['mid_band'] = mid_band\n",
    "    df['d_ema'] = d_ema\n",
    "    df['ht_trend'] = ht_trend\n",
    "    df['kama'] = kama\n",
    "    df['ma'] = ma\n",
    "    #df['mama'] = mama\n",
    "    df['mid'] = mid\n",
    "    df['mid_price'] = mid_price\n",
    "\n",
    "    df['sar'] = sar\n",
    "    df['sarext'] = sarext\n",
    "    df['sma'] = sma\n",
    "    df['tema'] = tema\n",
    "    df['trima'] = trima\n",
    "    df['wma'] = wma\n",
    "    #df['fama'] = fama\n",
    "\n",
    "    df['EMA'] = E_M_A\n",
    "    df['SlowK'] = slowk\n",
    "    df['SlowD'] = slowd\n",
    "    df['R_S_I'] = R_S_I\n",
    "    df['FastK'] = fastk\n",
    "    df['FastD'] = fastd\n",
    "    df['WilliamsR'] = real\n",
    "\n",
    "    df['atr'] = atr\n",
    "    df['natr'] = natr\n",
    "    df['t_range'] = t_range\n",
    "\n",
    "\n",
    "    #df['na_tr'] = natr\n",
    "\n",
    "    df['OBV'] = O_B_V\n",
    "    df['ADOSC'] = A_D_O_S_C\n",
    "    df['ogchaikin'] = O_G_chaikin\n",
    "    df['HTDCperiod'] = HT_DCper\n",
    "    df['HTDCphase'] = HT_DCphase\n",
    "    df['inphase'] = inphase\n",
    "    df['quad'] = quad\n",
    "    df['rsin'] = r_sin\n",
    "    df['leadsin'] = leadsin\n",
    "\n",
    "    df['mfi'] = mfi\n",
    "    df['min_di'] = min_di\n",
    "    df['min_dm'] = min_dm\n",
    "    df['momo'] = momo\n",
    "    df['plus_di'] = plus_di\n",
    "    df['plus_dm'] = plus_dm\n",
    "    df['ppo'] = ppo\n",
    "    df['roc'] = roc\n",
    "    df['rocp'] = rocp\n",
    "\n",
    "    df['rocr'] = rocr\n",
    "    df['rocr_hund'] = rocr_hund\n",
    "    df['rsi_fastk'] = rsi_fastk\n",
    "    df['rsi_fastd'] = rsi_fastd\n",
    "    df['trix'] = trix\n",
    "    df['ult_osc'] = ult_osc\n",
    "\n",
    "    df['adx'] = adx\n",
    "    df['adxr'] = adxr\n",
    "    df['apo'] = apo\n",
    "    df['aroon_d'] = aroon_d\n",
    "    df['aroon_u'] = aroon_u\n",
    "    df['aroon_osc'] = aroon_osc\n",
    "    df['bop'] = bop\n",
    "    df['cci'] = cci\n",
    "    df['cmo'] = cmo\n",
    "\n",
    "    df['dx'] = dx\n",
    "    df['macd'] = macd\n",
    "    df['macdsig'] = macdsig\n",
    "    df['macdhist'] = macdhist\n",
    "    df['macdex'] = macdex\n",
    "    df['macdexsig'] = macdexsig\n",
    "    df['macdexhist'] = macdexhist\n",
    "    df['macdfixd'] = macdfixd\n",
    "    df['macdfixdsig'] = macdfixdsig\n",
    "    df['macdfixdhist'] = macdfixdhist\n",
    "\n",
    "    df['two_crows'] = two_crows\n",
    "    df['three_crows'] = three_crows\n",
    "    df['three_inside'] = three_inside\n",
    "    df['three_line'] = three_line\n",
    "    df['three_out'] = three_out\n",
    "    df['three_stars'] = three_stars\n",
    "    df['three_soldier'] = three_soldier\n",
    "    df['baby'] = baby\n",
    "    df['adv'] = adv\n",
    "    df['belt_hold'] = belt_hold\n",
    "    df['breakaway'] = breakaway\n",
    "    df['closingmara'] = closingmara\n",
    "    df['baby_swallow'] = belt_hold\n",
    "\n",
    "    df['counter'] = counter\n",
    "    df['dark_cloud'] = dark_cloud\n",
    "    df['doji'] = doji\n",
    "    df['doji_star'] = doji_star\n",
    "    df['dragon_doji'] = dragon_doji\n",
    "    df['engulf'] = engulf\n",
    "    df['evening_star'] = evening_star\n",
    "    df['gapside'] = gapside\n",
    "    df['gravestone'] = gravestone\n",
    "    df['hammer'] = hammer\n",
    "    df['hang_man'] = hang_man\n",
    "    df['harami'] = harami\n",
    "    df['harami_cross'] = harami_cross\n",
    "\n",
    "    df['high_wave'] = high_wave\n",
    "    df['hikkake'] = hikkake\n",
    "    df['hikkake_mod'] = hikkake_mod\n",
    "    df['pidgeon'] = pidgeon\n",
    "    df['id_three_crows'] = id_three_crows\n",
    "    df['in_neck'] = in_neck\n",
    "    df['inv_hammer'] = inv_hammer\n",
    "    df['kicking'] = kicking\n",
    "    df['kicking_len'] = kicking_len\n",
    "    df['ladder_bot'] = ladder_bot\n",
    "    df['doji_long'] = doji_long\n",
    "    df['long_line'] = long_line\n",
    "    df['marabozu'] = marabozu\n",
    "                                                    # this is  a comment\n",
    "    df['match_glow'] = match_glow\n",
    "    df['mat_hold'] = mat_hold\n",
    "    df['morning_doji'] = morning_doji\n",
    "    df['morning_star'] = morning_star\n",
    "    df['on_neck'] = on_neck\n",
    "    df['pierce'] = pierce\n",
    "    df['rickshaw'] = rickshaw\n",
    "    df['rise_fall'] = rise_fall\n",
    "    df['sep_line'] = sep_line\n",
    "    df['shooting_star'] = shooting_star\n",
    "    df['sl_candle'] = sl_candle\n",
    "    df['spin_top'] = spin_top\n",
    "    df['stalled'] = stalled\n",
    "\n",
    "    df['stick_sand'] = stick_sand\n",
    "    df['takuri'] = takuri\n",
    "    df['tasuki_gap'] = tasuki_gap\n",
    "    df['thrust'] = thrust\n",
    "    df['tristar'] = tristar\n",
    "    df['three_river'] = three_river\n",
    "    df['ud_two_gap'] = ud_two_gap\n",
    "    df['down_three_gap'] = down_three_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag(num_lag_cols, this_df):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    lag_cols = ['ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc','adj_close', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line', 'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows','in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                'mid_band','d_ema','ht_trend','kama','ma','mid','mid_price','sar','sarext','sma','tema','trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix','ult_osc', 'atr','natr','t_range'\n",
    "                ]\n",
    "\n",
    "    shift_range = [x+1 for x in range(num_lag_cols)]\n",
    "\n",
    "    for shift in shift_range:\n",
    "        train_shift = this_df[merging_keys + lag_cols].copy()\n",
    "\n",
    "        # E.g. order_day of 0 becomes 1, for shift = 1.\n",
    "        # So when this is merged with order_day of 1 in df, this will represent lag of 1.\n",
    "        train_shift['order_day'] = train_shift['order_day'] + shift\n",
    "\n",
    "        foo = lambda x: '{}_lag_{}'.format(x, shift) if x in lag_cols else x\n",
    "        train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "        this_df = pd.merge(this_df, train_shift, on=merging_keys, how='left') #.fillna(0)\n",
    "\n",
    "    del train_shift\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "\n",
    "    print(f\"completed lagging in {tic_toc:0.4f} min\")\n",
    "    \n",
    "\n",
    "    return this_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_test_labels(df, window_size):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    '''df.loc[df['adj_close'] >= df['adj_close'].rolling(window_size).max(), 'test_labels'] = 0\n",
    "    df.loc[df['adj_close'] <= df['adj_close'].rolling(window_size).min(), 'test_labels'] = 1'''\n",
    "    # interesting use of quantile\n",
    "    # could also attempt to implement STD dev here, though choosing quantiles / std dev should produce the same result\n",
    "    # might try to use a larger window size to capture more of the true \"dips\"\n",
    "    df.loc[df['adj_close'] >= df['adj_close'].rolling((window_size*2)).quantile(.95, interpolation='linear'), 'test_labels'] = 0 # sell\n",
    "    \n",
    "    df.loc[df['adj_close'] <= df['adj_close'].rolling(round((window_size/2))).quantile(.05, interpolation='linear'), 'test_labels'] = 1 #buy\n",
    "    df['test_labels'].fillna(2, inplace = True)\n",
    "    \n",
    "    \n",
    "    #list_test_labels = df['test_labels']\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "    \n",
    "    #BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "    print(f\"completed labels in {tic_toc:0.4f} min\")\n",
    "    \n",
    "    #return list_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_test_labels_daily(df, window_size):\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    '''df.loc[df['adj_close'] >= df['adj_close'].rolling(window_size).max(), 'test_labels'] = 0\n",
    "    df.loc[df['adj_close'] <= df['adj_close'].rolling(window_size).min(), 'test_labels'] = 1'''\n",
    "    # interesting use of quantile\n",
    "    # could also attempt to implement STD dev here, though choosing quantiles / std dev should produce the same result\n",
    "    # might try to use a larger window size to capture more of the true \"dips\"\n",
    "    df.loc[df['adj_close'] >= df['adj_close'].rolling((window_size*2)).quantile(.95, interpolation='linear'), 'test_labels'] = 0\n",
    "    df.loc[df['adj_close'] <= df['adj_close'].rolling(round((window_size/2))).quantile(.05, interpolation='linear'), 'test_labels'] = 1\n",
    "    df['test_labels'].fillna(2, inplace = True)\n",
    "    \n",
    "    \n",
    "    #list_test_labels = df['test_labels']\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    tic_toc = (toc - tic) / 60\n",
    "    \n",
    "    #BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "    print(f\"completed labels in {tic_toc:0.4f} min\")\n",
    "    \n",
    "    #return list_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-python",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scale(num_interval_lag):\n",
    "\n",
    "    cols_to_scale = ['ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                    'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line', 'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                    'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                    'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows','in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                    'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                    'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                    'mid_band','d_ema','ht_trend','kama','ma','mid','mid_price','sar','sarext','sma','tema','trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                    'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                    'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix','ult_osc', 'atr','natr','t_range'\n",
    "                    ]\n",
    "\n",
    "    for i in range(1,num_interval_lag+1):\n",
    "        cols_to_scale.append(\"ema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"slowd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"r_s_i_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"fastk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"fastd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"williamsr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"volume_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"range_hl_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"range_oc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adj_close_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"upper_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"lower_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_band_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"d_ema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ht_trend_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kama_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ma_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"mid_price_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sar_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sarext_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sma_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tema_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"trima_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"wma_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"atr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"natr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"t_range_lag_\"+str(i))\n",
    "\n",
    "        #momentum indicator lag cols\n",
    "\n",
    "        cols_to_scale.append(\"adx_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adxr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"apo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_d_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_u_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"aroon_osc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"bop_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"cci_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"cmo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"dx_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdhist_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdex_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"mfi_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"min_di_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"min_dm_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"momo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"plus_di_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"plus_dm_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ppo_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"roc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocp_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocr_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rocr_hund_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsi_fastk_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsi_fastd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"trix_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ult_osc_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"macdexsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdexhist_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixd_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixdsig_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"macdfixdhist_lag_\"+str(i))\n",
    "\n",
    "\n",
    "        #cols_to_scale.append(\"mama_lag_\"+str(i))\n",
    "        #cols_to_scale.append(\"NATR_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"obv_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"adosc_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ogchaikin_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"htdcperiod_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"htdcphase_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"inphase_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"quad_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rsin_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"leadsin_lag_\"+str(i))\n",
    "        #cols_to_scale.append(\"fama_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"two_crows_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"three_crows_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_inside_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_out_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_stars_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_soldier_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"baby_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"adv_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"belt_hold_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"breakaway_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"closingmara_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"baby_swallow_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"counter_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"dark_cloud_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"dragon_doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"engulf_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"evening_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"gapside_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"gravestone_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hammer_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hang_man_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"harami_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"harami_cross_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"high_wave_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"hikkake_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"hikkake_mod_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"pidgeon_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"id_three_crows_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"in_neck_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"inv_hammer_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kicking_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"kicking_len_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ladder_bot_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"doji_long_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"long_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"marabozu_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"match_glow_lag_\" +str(i))\n",
    "        cols_to_scale.append(\"mat_hold_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"morning_doji_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"morning_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"on_neck_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"pierce_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rickshaw_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"rise_fall_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sep_line_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"shooting_star_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"sl_candle_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"spin_top_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"stalled_lag_\"+str(i))\n",
    "\n",
    "        cols_to_scale.append(\"stick_sand_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"takuri_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tasuki_gap_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"thrust_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"tristar_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"three_river_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"ud_two_gap_lag_\"+str(i))\n",
    "        cols_to_scale.append(\"down_three_gap_lag_\"+str(i))\n",
    "\n",
    "    return cols_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(type(df['test_labels'].rolling(20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-burner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'JPM'\n",
    "\n",
    "\n",
    "# You will need to drop the non lagged columns > they are a data leak to the current adj_close\n",
    "\n",
    "\n",
    "start_date = datetime.datetime.now() - datetime.timedelta(days=59)\n",
    "\n",
    "end_date = datetime.datetime.now()\n",
    "\n",
    "df = pdr.get_data_yahoo(stock, start=start_date, end=end_date, interval = \"2m\", prepost=True)\n",
    "\n",
    "#df = pdr.get_data_yahoo(stock, period = \"max\", interval = \"1d\", prepost = True)\n",
    "\n",
    "#df.index = df.index.tz_localize(None)\n",
    "\n",
    "'''#2 min ticker\n",
    "# 30 intervals = 1 hour << OLD\n",
    "# 195 intervals = trading day'''\n",
    "                                            # there are more intervals that we can use / change\n",
    "really_fast = 30\n",
    "fast = 60\n",
    "slow = 90\n",
    "\n",
    "add_indicators()\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "# Change all column headings to be lower case, and remove spacing\n",
    "df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n",
    "\n",
    "# Get difference between high and low of each day\n",
    "df['range_hl'] = df['high'] - df['low']\n",
    "df.drop(['high', 'low'], axis=1, inplace=True)\n",
    "# Get difference between open and close of each day\n",
    "df['range_oc'] = df['open'] - df['adj_close']\n",
    "df.drop(['open'], axis=1, inplace=True)\n",
    "# Add a column 'order_day' to indicate the order of the rows by date\n",
    "df['order_day'] = [x for x in list(range(len(df)))]\n",
    "# merging_keys\n",
    "merging_keys = ['order_day']\n",
    "\n",
    "num_interval_lag = 60\n",
    "\n",
    "df = add_lag(num_interval_lag, df)\n",
    "\n",
    "#df['adj_close'] = df['adj_close'].shift(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-delight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#df.tail(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_labels(df)\n",
    "#1 day - 195, 2 = 390, 3 = 585, 4 = 780, 5 = 975\n",
    "#6 = 1170, 7 = 1365, 8 = 1560, 9 = 1755, 10 = 1950\n",
    "window_size = 975\n",
    "add_test_labels(df, window_size)\n",
    "\n",
    "\n",
    "#print(df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_labels(df)\n",
    "# for daily time windows\n",
    "window_size = 5\n",
    "add_test_labels_daily(df, window_size)\n",
    "\n",
    "\n",
    "#print(df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['test_labels'] = df['test_labels'].shift(-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-basics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test_labels'].value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rem = ['ema', 'slowk','slowd','r_s_i','fastk','fastd','williamsr','volume','range_hl','range_oc','adj_close', 'obv', 'adosc', 'ogchaikin', 'htdcperiod','htdcphase',\n",
    "                'inphase','quad','rsin','leadsin', 'two_crows', 'three_crows', 'three_inside', 'three_line', 'three_out', 'three_stars', 'three_soldier', 'baby', 'adv', 'belt_hold',\n",
    "                'breakaway', 'closingmara', 'baby_swallow', 'counter','dark_cloud','doji','doji_star','dragon_doji','engulf','evening_star','gapside','gravestone','hammer',\n",
    "                'hang_man','harami','harami_cross','high_wave','hikkake','hikkake_mod','pidgeon','id_three_crows','in_neck','inv_hammer','kicking','kicking_len','ladder_bot',\n",
    "                'doji_long','long_line','marabozu', 'match_glow','mat_hold','morning_doji','morning_star','on_neck','pierce','rickshaw','rise_fall','sep_line','shooting_star',\n",
    "                'sl_candle','spin_top','stalled','stick_sand','takuri','tasuki_gap','thrust','tristar','three_river','ud_two_gap','down_three_gap', 'upper_band','lower_band',\n",
    "                'mid_band','d_ema','ht_trend','kama','ma','mid','mid_price','sar','sarext','sma','tema','trima','wma','adx','adxr','apo','aroon_d','aroon_u','aroon_osc',\n",
    "                'bop','cci','cmo','dx','macd','macdsig','macdhist','macdex','macdexsig','macdexhist','macdfixd','macdfixdsig','macdfixdhist','mfi','min_di','min_dm',\n",
    "                'momo','plus_di','plus_dm','ppo','roc','rocp','rocr','rocr_hund','rsi_fastk','rsi_fastd','trix','ult_osc', 'atr','natr','t_range'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-staff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-elder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_vals_list = df['adj_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols_to_rem, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#close_vals_list = df['adj_close']\n",
    "\n",
    "#df.drop(['adj_close'], axis=1, inplace=True)\n",
    "\n",
    "#df.fillna(0, inplace=True)\n",
    "\n",
    "#BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "num_test = int(.2*len(df))\n",
    "num_train = len(df) - num_test\n",
    "\n",
    "# Split into train, cv, and test\n",
    "train = df[:num_train]\n",
    "test = df[num_train:]\n",
    "\n",
    "#print(test['datetime'].iloc[[-1]])\n",
    "print(test['test_labels'].iloc[[-1]])\n",
    "\n",
    "train_close_vals = close_vals_list[:num_train]\n",
    "test_close_vals = close_vals_list[num_train:]\n",
    "\n",
    "#test_dates_list = test['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates_list = test['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dates_list = test['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-limitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = add_scale(num_interval_lag)\n",
    "\n",
    "#cols_to_scale.remove(cols_to_rem)\n",
    "\n",
    "# Do scaling for train set\n",
    "# Here we only scale the train dataset, and not the entire dataset to prevent information leak\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in cols_to_rem:\n",
    "\n",
    "    if element in cols_to_scale:\n",
    "\n",
    "        cols_to_scale.remove(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train[cols_to_scale])\n",
    "train_scaled = scaler.transform(train[cols_to_scale])\n",
    "\n",
    "# Convert the numpy array back into pandas dataframe\n",
    "\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=cols_to_scale)\n",
    "\n",
    "train_scaled = train_scaled[slow:]\n",
    "train = train[slow:]\n",
    "\n",
    "#scaling test dataset\n",
    "\n",
    "scaler_2 = StandardScaler()\n",
    "scaler_2.fit(test[cols_to_scale])\n",
    "test_scaled = scaler_2.transform(test[cols_to_scale])\n",
    "\n",
    "# Convert the numpy array back into pandas dataframe\n",
    "\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=cols_to_scale)\n",
    "\n",
    "features = cols_to_scale\n",
    "#features.remove(target)\n",
    "\n",
    "# Split into X and y\n",
    "'''X_train_scaled = train_scaled[features]\n",
    "y_train_scaled = train['labels']\n",
    "\n",
    "X_test_scaled = test_scaled[features]\n",
    "y_test_scaled = test['labels']'''\n",
    "\n",
    "X_train_scaled_new = train_scaled[features]\n",
    "y_train_scaled_new = train['test_labels']\n",
    "\n",
    "X_test_scaled_new = test_scaled[features]\n",
    "y_test_scaled_new = test['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(y_test_scaled))\n",
    "#print(y_test_scaled)\n",
    "\n",
    "temp = y_test_scaled_new.to_numpy()\n",
    "true_temp_frame = pd.DataFrame(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scaled_new.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [18, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list_true = true_temp_frame.index[y_test_scaled_new==1].tolist()\n",
    "sell_list_true = true_temp_frame.index[y_test_scaled_new==0].tolist()\n",
    "\n",
    "plt.plot(test_dates_list, test_close_vals)\n",
    "plt.plot(test_dates_list, test_close_vals, 'g^', markevery=buy_list_true)\n",
    "plt.plot(test_dates_list, test_close_vals, 'rv', markevery=sell_list_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(inplace=True)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(df['test_labels'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_train_scaled_new, y_train_scaled_new), (X_test_scaled_new, y_test_scaled_new)]\n",
    "eval_metric = ['mlogloss','merror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model = XGBClassifier(n_estimators=200,\n",
    "                    use_label_encoder = False,\n",
    "                    max_depth=20,\n",
    "                    learning_rate=0.1,\n",
    "                    objective = 'multi:softmax',\n",
    "                    min_child_weight=1,\n",
    "                    subsample=1,\n",
    "                    colsample_bytree=1,\n",
    "                    colsample_bylevel=1,\n",
    "                    num_class=3,\n",
    "                    gamma=0.1)\n",
    "\n",
    "# Train the regressor\n",
    "\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "test_pred = model.predict(X_test_scaled)'''\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "model_2 = XGBClassifier(n_estimators=100,\n",
    "                    use_label_encoder = False,\n",
    "                    max_depth=10,\n",
    "                    learning_rate=0.1,\n",
    "                    objective = 'multi:softprob',\n",
    "                    n_jobs=16,\n",
    "                    min_child_weight=1,\n",
    "                    subsample=1,\n",
    "                    colsample_bytree=1,\n",
    "                    colsample_bylevel=1,\n",
    "                    num_class = 3,\n",
    "                    gamma=0.1,\n",
    "                    verbosity = 0)\n",
    "\n",
    "# Train the regressor\n",
    "\n",
    "model_2.fit(X_train_scaled_new, y_train_scaled_new, eval_set = eval_set, eval_metric = eval_metric, verbose=False)\n",
    "\n",
    "test_pred_2 = model_2.predict(X_test_scaled_new)\n",
    "\n",
    "#train_scaled['labels'] = train_pred\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "tic_toc = (toc - tic) / 60\n",
    "\n",
    "print(f\"completed train in {tic_toc:0.4f} min\")\n",
    "\n",
    "''' there is some consideration to be made if we can grab the top 20-30 most influential features from xgboost and use them to train a different model type'''\n",
    "''' there is also consideration to be made about exporting these models'''\n",
    "\n",
    "\n",
    "# this methodology works for saving a trained model\n",
    "#pickle.dump(model, open(\"test.model\", \"wb\"))\n",
    "\n",
    "#unscaling\n",
    "#pred_unscaled = scaler_2.inverse_transform(test_scaled)\n",
    "#plt.figure()\n",
    "#plotting\n",
    "\n",
    "#plt.plot(train_scaled.index, train[target])\n",
    "#plt.plot(train_scaled.index, train_scaled[target])\n",
    "\n",
    "\n",
    "#plt.plot(test_scaled.index, test['labels'])\n",
    "#plt.plot(test_scaled.index, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_2.evals_result()\n",
    "epochs = len(results['validation_0']['merror'])\n",
    "x_axis = range(0, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['mlogloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['mlogloss'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('logloss')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.title('XGBoost logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['merror'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['merror'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('merror')\n",
    "plt.title('XGBoost merror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model_2, max_num_features = 50)\n",
    "xgb.plot_tree(model_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = model_2.get_booster().get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keys = sorted(feature_dict, key=feature_dict.get, reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-married",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-participation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_frame = pd.DataFrame(test_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scaled_new.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_frame.value_counts()\n",
    "#BUY => 1, SELL => 0, HOLD => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = X_train_scaled_new.to_numpy()\n",
    "#print(type(X_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import count_nonzero\n",
    "sparsity = 1.0 - (count_nonzero(X_numpy) / X_numpy.size)\n",
    "print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = (X_train_scaled_new.to_numpy() == 0).mean()\n",
    "#print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import f1_score\n",
    "#f1_score(y_test_scaled_new.values.tolist(), test_pred_2.tolist(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(pred_frame.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Sell', 'Buy', 'Hold']\n",
    "print(classification_report(y_test_scaled_new.values.tolist(), test_pred_2.tolist(), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-producer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_scaled_new.values.tolist(), test_pred_2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_2, X_test_scaled_new, y_test_scaled_new,display_labels=['Sell','Buy','Hold'],normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred_2[-1])\n",
    "#last class label\n",
    "#plt.ylabel('BUY => 1, SELL => 0, HOLD => 2')\n",
    "test_dates_list[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list = pred_frame.index[pred_frame[0]==1].tolist()\n",
    "sell_list = pred_frame.index[pred_frame[0]==0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_list_true = pred_frame.index[y_test_scaled_new==1].tolist()\n",
    "sell_list_true = pred_frame.index[y_test_scaled_new==0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-packet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(test_dates_list, test_close_vals)\n",
    "plt.plot(test_dates_list, test_close_vals, 'g^', markevery=buy_list)\n",
    "plt.plot(test_dates_list, test_close_vals, 'rv', markevery=sell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-round",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(test_dates_list, test_close_vals)\n",
    "plt.plot(test_dates_list, test_close_vals, 'g^', markevery=buy_list_true)\n",
    "plt.plot(test_dates_list, test_close_vals, 'rv', markevery=sell_list_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-medicare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-portuguese",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
